{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmY88kKIkIkS",
        "outputId": "b35761b2-6b0b-48d5-c840-bae433fb98b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.11.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "D2WvlD20Lryu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e011e6-1f56-48e4-a812-d9008c98b239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn import metrics\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "from binary_load import binary_load_dataset\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers as Layer\n",
        "from tensorflow.keras.metrics import Recall, Precision, BinaryAccuracy, TruePositives, TrueNegatives, FalsePositives, FalseNegatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J40s4y5fy8MF"
      },
      "outputs": [],
      "source": [
        "csv_loca = \"star.csv\"\n",
        "TEST_SIZE = 0.2\n",
        "VAL_SIZE = 0.2\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u_q84By2zyAH"
      },
      "outputs": [],
      "source": [
        "def modelling(nodes1 = 8, nodes2= 6, nodes3 = 4, drop_rate= 0.2, activation= 'relu'):\n",
        "  # 모델 만들기\n",
        "  # 뉴런의 개수는 input과 output 사이의 숫자를 넣으라고 한다. --> 사용, 왜냐하면 시간이 적게 걸려서\n",
        "  # 뉴런의 개수는 input의 2/3 정도 넣라고 한다.\n",
        "  # 뉴런의 개수는 input의 두배보다는 적게 넣라고 한다.\n",
        "\n",
        "  model = Sequential([Layer.Dense(12, input_shape=(8,))])\n",
        "  model.add(Layer.Dense(nodes1, activation = activation))\n",
        "  model.add(Layer.BatchNormalization())\n",
        "  model.add(Layer.Dropout(drop_rate))\n",
        "\n",
        "  model.add(Layer.Dense(nodes2, activation = activation))\n",
        "  model.add(Layer.BatchNormalization())\n",
        "  model.add(Layer.Dropout(drop_rate))\n",
        "\n",
        "  model.add(Layer.Dense(nodes3, activation = activation))\n",
        "  model.add(Layer.BatchNormalization())\n",
        "  model.add(Layer.Dropout(drop_rate))\n",
        "\n",
        "  model.add(Layer.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "  metrics = [\n",
        "      TruePositives(name = 'tp'),\n",
        "      TrueNegatives(name = 'tn'),\n",
        "      FalsePositives(name = 'fp'),\n",
        "      FalseNegatives(name = 'fn'),\n",
        "      Recall(name = 'recall'),\n",
        "      Precision(name = 'precision'),\n",
        "      BinaryAccuracy(name = 'binary accuracy') # Binary Accuracy를 사용 안 하는 이유는 accuracy가 자동적으로 Binary Accuracy로 compile할 때 바꾸기 때문.\n",
        "  ]\n",
        "\n",
        "  model.compile(optimizer = 'adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics = metrics)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rudcT08TGqV",
        "outputId": "e3752b59-fed7-4e34-ae88-d7ac4bddbf15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11454, 8), (11454,), (2864, 8), (2864,), (3580, 8), (3580,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = binary_load_dataset(csv_loca, TEST_SIZE, VAL_SIZE, RANDOM_STATE)\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = modelling()\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ym-v7YYpspY8",
        "outputId": "f415d368-f746-4748-eac8-a89beba81659"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size= 1000, epochs= 1000,  validation_data=(X_val, y_val))\n",
        "\n",
        "\n",
        "model.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyotaIlztT-M",
        "outputId": "dcdd8bd4-b7a7-49f6-c617-5736fda419a4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1190 - tp: 736.0000 - tn: 10359.0000 - fp: 46.0000 - fn: 313.0000 - recall: 0.7016 - precision: 0.9412 - binary accuracy: 0.9687 - val_loss: 0.0966 - val_tp: 212.0000 - val_tn: 2583.0000 - val_fp: 19.0000 - val_fn: 50.0000 - val_recall: 0.8092 - val_precision: 0.9177 - val_binary accuracy: 0.9759\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.1182 - tp: 759.0000 - tn: 10349.0000 - fp: 56.0000 - fn: 290.0000 - recall: 0.7235 - precision: 0.9313 - binary accuracy: 0.9698 - val_loss: 0.1120 - val_tp: 228.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 34.0000 - val_recall: 0.8702 - val_precision: 0.8507 - val_binary accuracy: 0.9742\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1199 - tp: 772.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 277.0000 - recall: 0.7359 - precision: 0.9050 - binary accuracy: 0.9687 - val_loss: 0.1146 - val_tp: 229.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8388 - val_binary accuracy: 0.9731\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1162 - tp: 773.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 276.0000 - recall: 0.7369 - precision: 0.9224 - binary accuracy: 0.9702 - val_loss: 0.0973 - val_tp: 216.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 46.0000 - val_recall: 0.8244 - val_precision: 0.8926 - val_binary accuracy: 0.9749\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.1171 - tp: 759.0000 - tn: 10347.0000 - fp: 58.0000 - fn: 290.0000 - recall: 0.7235 - precision: 0.9290 - binary accuracy: 0.9696 - val_loss: 0.0915 - val_tp: 214.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 48.0000 - val_recall: 0.8168 - val_precision: 0.9145 - val_binary accuracy: 0.9763\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.1137 - tp: 769.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 280.0000 - recall: 0.7331 - precision: 0.9199 - binary accuracy: 0.9697 - val_loss: 0.0943 - val_tp: 218.0000 - val_tn: 2580.0000 - val_fp: 22.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.9083 - val_binary accuracy: 0.9770\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.1143 - tp: 771.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 278.0000 - recall: 0.7350 - precision: 0.9124 - binary accuracy: 0.9693 - val_loss: 0.0947 - val_tp: 217.0000 - val_tn: 2578.0000 - val_fp: 24.0000 - val_fn: 45.0000 - val_recall: 0.8282 - val_precision: 0.9004 - val_binary accuracy: 0.9759\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1145 - tp: 757.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 292.0000 - recall: 0.7216 - precision: 0.9088 - binary accuracy: 0.9679 - val_loss: 0.0926 - val_tp: 215.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 47.0000 - val_recall: 0.8206 - val_precision: 0.9149 - val_binary accuracy: 0.9766\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1187 - tp: 769.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 280.0000 - recall: 0.7331 - precision: 0.9232 - binary accuracy: 0.9700 - val_loss: 0.0936 - val_tp: 218.0000 - val_tn: 2580.0000 - val_fp: 22.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.9083 - val_binary accuracy: 0.9770\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1155 - tp: 771.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 278.0000 - recall: 0.7350 - precision: 0.9113 - binary accuracy: 0.9692 - val_loss: 0.0898 - val_tp: 215.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 47.0000 - val_recall: 0.8206 - val_precision: 0.9149 - val_binary accuracy: 0.9766\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1144 - tp: 779.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 270.0000 - recall: 0.7426 - precision: 0.9143 - binary accuracy: 0.9701 - val_loss: 0.0934 - val_tp: 219.0000 - val_tn: 2580.0000 - val_fp: 22.0000 - val_fn: 43.0000 - val_recall: 0.8359 - val_precision: 0.9087 - val_binary accuracy: 0.9773\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1151 - tp: 772.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 277.0000 - recall: 0.7359 - precision: 0.9125 - binary accuracy: 0.9694 - val_loss: 0.0901 - val_tp: 214.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 48.0000 - val_recall: 0.8168 - val_precision: 0.9145 - val_binary accuracy: 0.9763\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1119 - tp: 786.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 263.0000 - recall: 0.7493 - precision: 0.9087 - binary accuracy: 0.9701 - val_loss: 0.0911 - val_tp: 217.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 45.0000 - val_recall: 0.8282 - val_precision: 0.9156 - val_binary accuracy: 0.9773\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1088 - tp: 786.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 263.0000 - recall: 0.7493 - precision: 0.9225 - binary accuracy: 0.9713 - val_loss: 0.1019 - val_tp: 225.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 37.0000 - val_recall: 0.8588 - val_precision: 0.8755 - val_binary accuracy: 0.9759\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1133 - tp: 789.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 260.0000 - recall: 0.7521 - precision: 0.9069 - binary accuracy: 0.9702 - val_loss: 0.0889 - val_tp: 218.0000 - val_tn: 2581.0000 - val_fp: 21.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.9121 - val_binary accuracy: 0.9773\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1124 - tp: 770.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 279.0000 - recall: 0.7340 - precision: 0.9080 - binary accuracy: 0.9688 - val_loss: 0.0823 - val_tp: 208.0000 - val_tn: 2586.0000 - val_fp: 16.0000 - val_fn: 54.0000 - val_recall: 0.7939 - val_precision: 0.9286 - val_binary accuracy: 0.9756\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1091 - tp: 776.0000 - tn: 10347.0000 - fp: 58.0000 - fn: 273.0000 - recall: 0.7398 - precision: 0.9305 - binary accuracy: 0.9711 - val_loss: 0.0883 - val_tp: 218.0000 - val_tn: 2581.0000 - val_fp: 21.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.9121 - val_binary accuracy: 0.9773\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1111 - tp: 786.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 263.0000 - recall: 0.7493 - precision: 0.9014 - binary accuracy: 0.9695 - val_loss: 0.0964 - val_tp: 223.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 39.0000 - val_recall: 0.8511 - val_precision: 0.8956 - val_binary accuracy: 0.9773\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1107 - tp: 784.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 265.0000 - recall: 0.7474 - precision: 0.9011 - binary accuracy: 0.9694 - val_loss: 0.0882 - val_tp: 216.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 46.0000 - val_recall: 0.8244 - val_precision: 0.9153 - val_binary accuracy: 0.9770\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1077 - tp: 777.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 272.0000 - recall: 0.7407 - precision: 0.9098 - binary accuracy: 0.9695 - val_loss: 0.0909 - val_tp: 218.0000 - val_tn: 2577.0000 - val_fp: 25.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.8971 - val_binary accuracy: 0.9759\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1065 - tp: 805.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 244.0000 - recall: 0.7674 - precision: 0.9096 - binary accuracy: 0.9717 - val_loss: 0.0969 - val_tp: 224.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.8960 - val_binary accuracy: 0.9777\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1093 - tp: 793.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 256.0000 - recall: 0.7560 - precision: 0.9084 - binary accuracy: 0.9707 - val_loss: 0.0949 - val_tp: 223.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 39.0000 - val_recall: 0.8511 - val_precision: 0.8956 - val_binary accuracy: 0.9773\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1081 - tp: 790.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 259.0000 - recall: 0.7531 - precision: 0.9122 - binary accuracy: 0.9708 - val_loss: 0.0824 - val_tp: 211.0000 - val_tn: 2583.0000 - val_fp: 19.0000 - val_fn: 51.0000 - val_recall: 0.8053 - val_precision: 0.9174 - val_binary accuracy: 0.9756\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1069 - tp: 796.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 253.0000 - recall: 0.7588 - precision: 0.9213 - binary accuracy: 0.9720 - val_loss: 0.0810 - val_tp: 211.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 51.0000 - val_recall: 0.8053 - val_precision: 0.9254 - val_binary accuracy: 0.9763\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1037 - tp: 815.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 234.0000 - recall: 0.7769 - precision: 0.9178 - binary accuracy: 0.9732 - val_loss: 0.0807 - val_tp: 208.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 54.0000 - val_recall: 0.7939 - val_precision: 0.9244 - val_binary accuracy: 0.9752\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.1070 - tp: 777.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 272.0000 - recall: 0.7407 - precision: 0.9120 - binary accuracy: 0.9697 - val_loss: 0.0804 - val_tp: 208.0000 - val_tn: 2586.0000 - val_fp: 16.0000 - val_fn: 54.0000 - val_recall: 0.7939 - val_precision: 0.9286 - val_binary accuracy: 0.9756\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1068 - tp: 792.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 257.0000 - recall: 0.7550 - precision: 0.9041 - binary accuracy: 0.9702 - val_loss: 0.0831 - val_tp: 215.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 47.0000 - val_recall: 0.8206 - val_precision: 0.9149 - val_binary accuracy: 0.9766\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1035 - tp: 817.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 232.0000 - recall: 0.7788 - precision: 0.9180 - binary accuracy: 0.9734 - val_loss: 0.0815 - val_tp: 213.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 49.0000 - val_recall: 0.8130 - val_precision: 0.9142 - val_binary accuracy: 0.9759\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1111 - tp: 783.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 266.0000 - recall: 0.7464 - precision: 0.9179 - binary accuracy: 0.9707 - val_loss: 0.0805 - val_tp: 213.0000 - val_tn: 2583.0000 - val_fp: 19.0000 - val_fn: 49.0000 - val_recall: 0.8130 - val_precision: 0.9181 - val_binary accuracy: 0.9763\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1096 - tp: 814.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 235.0000 - recall: 0.7760 - precision: 0.9044 - binary accuracy: 0.9720 - val_loss: 0.0803 - val_tp: 213.0000 - val_tn: 2583.0000 - val_fp: 19.0000 - val_fn: 49.0000 - val_recall: 0.8130 - val_precision: 0.9181 - val_binary accuracy: 0.9763\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1050 - tp: 802.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 247.0000 - recall: 0.7645 - precision: 0.9261 - binary accuracy: 0.9728 - val_loss: 0.0800 - val_tp: 211.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 51.0000 - val_recall: 0.8053 - val_precision: 0.9254 - val_binary accuracy: 0.9763\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1063 - tp: 801.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 248.0000 - recall: 0.7636 - precision: 0.9133 - binary accuracy: 0.9717 - val_loss: 0.0799 - val_tp: 213.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 49.0000 - val_recall: 0.8130 - val_precision: 0.9261 - val_binary accuracy: 0.9770\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1022 - tp: 814.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 235.0000 - recall: 0.7760 - precision: 0.9219 - binary accuracy: 0.9735 - val_loss: 0.0794 - val_tp: 211.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 51.0000 - val_recall: 0.8053 - val_precision: 0.9254 - val_binary accuracy: 0.9763\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1024 - tp: 830.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 219.0000 - recall: 0.7912 - precision: 0.9002 - binary accuracy: 0.9728 - val_loss: 0.0808 - val_tp: 217.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 45.0000 - val_recall: 0.8282 - val_precision: 0.9156 - val_binary accuracy: 0.9773\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1023 - tp: 825.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 224.0000 - recall: 0.7865 - precision: 0.8987 - binary accuracy: 0.9723 - val_loss: 0.0801 - val_tp: 214.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 48.0000 - val_recall: 0.8168 - val_precision: 0.9145 - val_binary accuracy: 0.9763\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1009 - tp: 814.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 235.0000 - recall: 0.7760 - precision: 0.9105 - binary accuracy: 0.9725 - val_loss: 0.0790 - val_tp: 213.0000 - val_tn: 2583.0000 - val_fp: 19.0000 - val_fn: 49.0000 - val_recall: 0.8130 - val_precision: 0.9181 - val_binary accuracy: 0.9763\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1080 - tp: 818.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 231.0000 - recall: 0.7798 - precision: 0.9109 - binary accuracy: 0.9728 - val_loss: 0.0789 - val_tp: 214.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 48.0000 - val_recall: 0.8168 - val_precision: 0.9264 - val_binary accuracy: 0.9773\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1017 - tp: 829.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 220.0000 - recall: 0.7903 - precision: 0.9170 - binary accuracy: 0.9742 - val_loss: 0.0784 - val_tp: 212.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 50.0000 - val_recall: 0.8092 - val_precision: 0.9258 - val_binary accuracy: 0.9766\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1089 - tp: 803.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 246.0000 - recall: 0.7655 - precision: 0.9167 - binary accuracy: 0.9721 - val_loss: 0.0782 - val_tp: 210.0000 - val_tn: 2586.0000 - val_fp: 16.0000 - val_fn: 52.0000 - val_recall: 0.8015 - val_precision: 0.9292 - val_binary accuracy: 0.9763\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1050 - tp: 819.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 230.0000 - recall: 0.7807 - precision: 0.9080 - binary accuracy: 0.9727 - val_loss: 0.0800 - val_tp: 218.0000 - val_tn: 2581.0000 - val_fp: 21.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.9121 - val_binary accuracy: 0.9773\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1018 - tp: 829.0000 - tn: 10307.0000 - fp: 98.0000 - fn: 220.0000 - recall: 0.7903 - precision: 0.8943 - binary accuracy: 0.9722 - val_loss: 0.0793 - val_tp: 216.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 46.0000 - val_recall: 0.8244 - val_precision: 0.9153 - val_binary accuracy: 0.9770\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1043 - tp: 814.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 235.0000 - recall: 0.7760 - precision: 0.8985 - binary accuracy: 0.9715 - val_loss: 0.0779 - val_tp: 212.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 50.0000 - val_recall: 0.8092 - val_precision: 0.9258 - val_binary accuracy: 0.9766\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1030 - tp: 811.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 238.0000 - recall: 0.7731 - precision: 0.9133 - binary accuracy: 0.9725 - val_loss: 0.0800 - val_tp: 219.0000 - val_tn: 2579.0000 - val_fp: 23.0000 - val_fn: 43.0000 - val_recall: 0.8359 - val_precision: 0.9050 - val_binary accuracy: 0.9770\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1014 - tp: 829.0000 - tn: 10308.0000 - fp: 97.0000 - fn: 220.0000 - recall: 0.7903 - precision: 0.8952 - binary accuracy: 0.9723 - val_loss: 0.0966 - val_tp: 232.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8657 - val_binary accuracy: 0.9770\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1069 - tp: 836.0000 - tn: 10302.0000 - fp: 103.0000 - fn: 213.0000 - recall: 0.7969 - precision: 0.8903 - binary accuracy: 0.9724 - val_loss: 0.0851 - val_tp: 226.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.8968 - val_binary accuracy: 0.9784\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1002 - tp: 816.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 233.0000 - recall: 0.7779 - precision: 0.9097 - binary accuracy: 0.9726 - val_loss: 0.0781 - val_tp: 213.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 49.0000 - val_recall: 0.8130 - val_precision: 0.9261 - val_binary accuracy: 0.9770\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1043 - tp: 810.0000 - tn: 10309.0000 - fp: 96.0000 - fn: 239.0000 - recall: 0.7722 - precision: 0.8940 - binary accuracy: 0.9708 - val_loss: 0.0792 - val_tp: 219.0000 - val_tn: 2581.0000 - val_fp: 21.0000 - val_fn: 43.0000 - val_recall: 0.8359 - val_precision: 0.9125 - val_binary accuracy: 0.9777\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1020 - tp: 835.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9027 - binary accuracy: 0.9735 - val_loss: 0.0779 - val_tp: 213.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 49.0000 - val_recall: 0.8130 - val_precision: 0.9261 - val_binary accuracy: 0.9770\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1006 - tp: 835.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9206 - binary accuracy: 0.9750 - val_loss: 0.0799 - val_tp: 208.0000 - val_tn: 2586.0000 - val_fp: 16.0000 - val_fn: 54.0000 - val_recall: 0.7939 - val_precision: 0.9286 - val_binary accuracy: 0.9756\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0961 - tp: 830.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 219.0000 - recall: 0.7912 - precision: 0.9222 - binary accuracy: 0.9748 - val_loss: 0.0773 - val_tp: 215.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 47.0000 - val_recall: 0.8206 - val_precision: 0.9267 - val_binary accuracy: 0.9777\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0992 - tp: 829.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 220.0000 - recall: 0.7903 - precision: 0.9060 - binary accuracy: 0.9733 - val_loss: 0.0778 - val_tp: 218.0000 - val_tn: 2582.0000 - val_fp: 20.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.9160 - val_binary accuracy: 0.9777\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0987 - tp: 836.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 213.0000 - recall: 0.7969 - precision: 0.9107 - binary accuracy: 0.9742 - val_loss: 0.0839 - val_tp: 228.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 34.0000 - val_recall: 0.8702 - val_precision: 0.8941 - val_binary accuracy: 0.9787\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0975 - tp: 842.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 207.0000 - recall: 0.8027 - precision: 0.9132 - binary accuracy: 0.9749 - val_loss: 0.0825 - val_tp: 227.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 35.0000 - val_recall: 0.8664 - val_precision: 0.8937 - val_binary accuracy: 0.9784\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1014 - tp: 825.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 224.0000 - recall: 0.7865 - precision: 0.9026 - binary accuracy: 0.9727 - val_loss: 0.0910 - val_tp: 232.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8755 - val_binary accuracy: 0.9780\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0973 - tp: 831.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 218.0000 - recall: 0.7922 - precision: 0.9142 - binary accuracy: 0.9742 - val_loss: 0.0827 - val_tp: 226.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.8898 - val_binary accuracy: 0.9777\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1018 - tp: 834.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 215.0000 - recall: 0.7950 - precision: 0.9105 - binary accuracy: 0.9741 - val_loss: 0.0854 - val_tp: 228.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 34.0000 - val_recall: 0.8702 - val_precision: 0.8837 - val_binary accuracy: 0.9777\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0979 - tp: 834.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 215.0000 - recall: 0.7950 - precision: 0.9105 - binary accuracy: 0.9741 - val_loss: 0.0845 - val_tp: 229.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8876 - val_binary accuracy: 0.9784\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0979 - tp: 842.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 207.0000 - recall: 0.8027 - precision: 0.9025 - binary accuracy: 0.9740 - val_loss: 0.0842 - val_tp: 228.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 34.0000 - val_recall: 0.8702 - val_precision: 0.8837 - val_binary accuracy: 0.9777\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0979 - tp: 829.0000 - tn: 10308.0000 - fp: 97.0000 - fn: 220.0000 - recall: 0.7903 - precision: 0.8952 - binary accuracy: 0.9723 - val_loss: 0.0777 - val_tp: 220.0000 - val_tn: 2579.0000 - val_fp: 23.0000 - val_fn: 42.0000 - val_recall: 0.8397 - val_precision: 0.9053 - val_binary accuracy: 0.9773\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0991 - tp: 839.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 210.0000 - recall: 0.7998 - precision: 0.9100 - binary accuracy: 0.9744 - val_loss: 0.0791 - val_tp: 223.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 39.0000 - val_recall: 0.8511 - val_precision: 0.8920 - val_binary accuracy: 0.9770\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0969 - tp: 841.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 208.0000 - recall: 0.8017 - precision: 0.9141 - binary accuracy: 0.9749 - val_loss: 0.0783 - val_tp: 221.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 41.0000 - val_recall: 0.8435 - val_precision: 0.8911 - val_binary accuracy: 0.9763\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0940 - tp: 839.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 210.0000 - recall: 0.7998 - precision: 0.9110 - binary accuracy: 0.9745 - val_loss: 0.0793 - val_tp: 224.0000 - val_tn: 2577.0000 - val_fp: 25.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.8996 - val_binary accuracy: 0.9780\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1018 - tp: 824.0000 - tn: 10310.0000 - fp: 95.0000 - fn: 225.0000 - recall: 0.7855 - precision: 0.8966 - binary accuracy: 0.9721 - val_loss: 0.0824 - val_tp: 229.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8842 - val_binary accuracy: 0.9780\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0926 - tp: 841.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 208.0000 - recall: 0.8017 - precision: 0.9082 - binary accuracy: 0.9744 - val_loss: 0.0771 - val_tp: 221.0000 - val_tn: 2579.0000 - val_fp: 23.0000 - val_fn: 41.0000 - val_recall: 0.8435 - val_precision: 0.9057 - val_binary accuracy: 0.9777\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0982 - tp: 823.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 226.0000 - recall: 0.7846 - precision: 0.8985 - binary accuracy: 0.9721 - val_loss: 0.0792 - val_tp: 223.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 39.0000 - val_recall: 0.8511 - val_precision: 0.8884 - val_binary accuracy: 0.9766\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0953 - tp: 845.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 204.0000 - recall: 0.8055 - precision: 0.9115 - binary accuracy: 0.9750 - val_loss: 0.0763 - val_tp: 218.0000 - val_tn: 2580.0000 - val_fp: 22.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.9083 - val_binary accuracy: 0.9770\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0949 - tp: 840.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 209.0000 - recall: 0.8008 - precision: 0.9091 - binary accuracy: 0.9744 - val_loss: 0.0805 - val_tp: 227.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 35.0000 - val_recall: 0.8664 - val_precision: 0.8867 - val_binary accuracy: 0.9777\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0980 - tp: 835.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9106 - binary accuracy: 0.9742 - val_loss: 0.0773 - val_tp: 222.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 40.0000 - val_recall: 0.8473 - val_precision: 0.8952 - val_binary accuracy: 0.9770\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0986 - tp: 849.0000 - tn: 10310.0000 - fp: 95.0000 - fn: 200.0000 - recall: 0.8093 - precision: 0.8994 - binary accuracy: 0.9742 - val_loss: 0.0798 - val_tp: 226.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.8760 - val_binary accuracy: 0.9763\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0962 - tp: 844.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 205.0000 - recall: 0.8046 - precision: 0.9056 - binary accuracy: 0.9744 - val_loss: 0.0778 - val_tp: 226.0000 - val_tn: 2577.0000 - val_fp: 25.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.9004 - val_binary accuracy: 0.9787\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0946 - tp: 847.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9011 - binary accuracy: 0.9742 - val_loss: 0.0906 - val_tp: 234.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8417 - val_binary accuracy: 0.9749\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0978 - tp: 839.0000 - tn: 10309.0000 - fp: 96.0000 - fn: 210.0000 - recall: 0.7998 - precision: 0.8973 - binary accuracy: 0.9733 - val_loss: 0.0772 - val_tp: 225.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 37.0000 - val_recall: 0.8588 - val_precision: 0.8964 - val_binary accuracy: 0.9780\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0945 - tp: 835.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9106 - binary accuracy: 0.9742 - val_loss: 0.0771 - val_tp: 224.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.8960 - val_binary accuracy: 0.9777\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0938 - tp: 835.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9047 - binary accuracy: 0.9736 - val_loss: 0.0917 - val_tp: 234.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8509 - val_binary accuracy: 0.9759\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0943 - tp: 846.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 203.0000 - recall: 0.8065 - precision: 0.9029 - binary accuracy: 0.9743 - val_loss: 0.0849 - val_tp: 232.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8755 - val_binary accuracy: 0.9780\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0943 - tp: 854.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9056 - binary accuracy: 0.9752 - val_loss: 0.0844 - val_tp: 229.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8740 - val_binary accuracy: 0.9770\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0930 - tp: 848.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9148 - binary accuracy: 0.9756 - val_loss: 0.0850 - val_tp: 231.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8717 - val_binary accuracy: 0.9773\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0978 - tp: 845.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 204.0000 - recall: 0.8055 - precision: 0.9009 - binary accuracy: 0.9741 - val_loss: 0.0777 - val_tp: 226.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.8863 - val_binary accuracy: 0.9773\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0960 - tp: 835.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9116 - binary accuracy: 0.9742 - val_loss: 0.0782 - val_tp: 226.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.8828 - val_binary accuracy: 0.9770\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0991 - tp: 831.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 218.0000 - recall: 0.7922 - precision: 0.9013 - binary accuracy: 0.9730 - val_loss: 0.0816 - val_tp: 230.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 32.0000 - val_recall: 0.8779 - val_precision: 0.8779 - val_binary accuracy: 0.9777\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0896 - tp: 858.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9157 - binary accuracy: 0.9764 - val_loss: 0.0884 - val_tp: 233.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8473 - val_binary accuracy: 0.9752\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0921 - tp: 847.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9088 - binary accuracy: 0.9749 - val_loss: 0.1048 - val_tp: 237.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7953 - val_binary accuracy: 0.9700\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0928 - tp: 848.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9079 - binary accuracy: 0.9749 - val_loss: 0.0891 - val_tp: 233.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8535 - val_binary accuracy: 0.9759\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0936 - tp: 835.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9047 - binary accuracy: 0.9736 - val_loss: 0.0898 - val_tp: 235.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8423 - val_binary accuracy: 0.9752\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0945 - tp: 850.0000 - tn: 10308.0000 - fp: 97.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.8976 - binary accuracy: 0.9742 - val_loss: 0.0939 - val_tp: 235.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8246 - val_binary accuracy: 0.9731\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0981 - tp: 835.0000 - tn: 10305.0000 - fp: 100.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.8930 - binary accuracy: 0.9726 - val_loss: 0.1044 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0926 - tp: 841.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 208.0000 - recall: 0.8017 - precision: 0.9033 - binary accuracy: 0.9740 - val_loss: 0.1177 - val_tp: 239.0000 - val_tn: 2519.0000 - val_fp: 83.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7422 - val_binary accuracy: 0.9630\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0904 - tp: 848.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9138 - binary accuracy: 0.9755 - val_loss: 0.1174 - val_tp: 239.0000 - val_tn: 2518.0000 - val_fp: 84.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7399 - val_binary accuracy: 0.9626\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0934 - tp: 843.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 206.0000 - recall: 0.8036 - precision: 0.9074 - binary accuracy: 0.9745 - val_loss: 0.0978 - val_tp: 237.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8089 - val_binary accuracy: 0.9717\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0965 - tp: 842.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 207.0000 - recall: 0.8027 - precision: 0.9015 - binary accuracy: 0.9739 - val_loss: 0.0893 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0941 - tp: 844.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 205.0000 - recall: 0.8046 - precision: 0.9066 - binary accuracy: 0.9745 - val_loss: 0.0814 - val_tp: 232.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8821 - val_binary accuracy: 0.9787\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0960 - tp: 829.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 220.0000 - recall: 0.7903 - precision: 0.9140 - binary accuracy: 0.9740 - val_loss: 0.0949 - val_tp: 235.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8246 - val_binary accuracy: 0.9731\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0963 - tp: 852.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9045 - binary accuracy: 0.9749 - val_loss: 0.1157 - val_tp: 239.0000 - val_tn: 2519.0000 - val_fp: 83.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7422 - val_binary accuracy: 0.9630\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0952 - tp: 843.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 206.0000 - recall: 0.8036 - precision: 0.9084 - binary accuracy: 0.9746 - val_loss: 0.0909 - val_tp: 234.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8509 - val_binary accuracy: 0.9759\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0965 - tp: 834.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 215.0000 - recall: 0.7950 - precision: 0.9075 - binary accuracy: 0.9738 - val_loss: 0.1041 - val_tp: 237.0000 - val_tn: 2536.0000 - val_fp: 66.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7822 - val_binary accuracy: 0.9682\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0920 - tp: 859.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9052 - binary accuracy: 0.9756 - val_loss: 0.0804 - val_tp: 232.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8855 - val_binary accuracy: 0.9791\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0940 - tp: 838.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 211.0000 - recall: 0.7989 - precision: 0.9050 - binary accuracy: 0.9739 - val_loss: 0.0766 - val_tp: 228.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 34.0000 - val_recall: 0.8702 - val_precision: 0.8837 - val_binary accuracy: 0.9777\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0894 - tp: 851.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9092 - binary accuracy: 0.9753 - val_loss: 0.0777 - val_tp: 228.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 34.0000 - val_recall: 0.8702 - val_precision: 0.8837 - val_binary accuracy: 0.9777\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0979 - tp: 844.0000 - tn: 10304.0000 - fp: 101.0000 - fn: 205.0000 - recall: 0.8046 - precision: 0.8931 - binary accuracy: 0.9733 - val_loss: 0.0749 - val_tp: 224.0000 - val_tn: 2577.0000 - val_fp: 25.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.8996 - val_binary accuracy: 0.9780\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0905 - tp: 839.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 210.0000 - recall: 0.7998 - precision: 0.9031 - binary accuracy: 0.9738 - val_loss: 0.0770 - val_tp: 227.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 35.0000 - val_recall: 0.8664 - val_precision: 0.8902 - val_binary accuracy: 0.9780\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0922 - tp: 840.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 209.0000 - recall: 0.8008 - precision: 0.9071 - binary accuracy: 0.9742 - val_loss: 0.0760 - val_tp: 223.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 39.0000 - val_recall: 0.8511 - val_precision: 0.8920 - val_binary accuracy: 0.9770\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0922 - tp: 852.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9025 - binary accuracy: 0.9748 - val_loss: 0.0749 - val_tp: 221.0000 - val_tn: 2581.0000 - val_fp: 21.0000 - val_fn: 41.0000 - val_recall: 0.8435 - val_precision: 0.9132 - val_binary accuracy: 0.9784\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0914 - tp: 839.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 210.0000 - recall: 0.7998 - precision: 0.9179 - binary accuracy: 0.9751 - val_loss: 0.0854 - val_tp: 234.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8540 - val_binary accuracy: 0.9763\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0954 - tp: 832.0000 - tn: 10311.0000 - fp: 94.0000 - fn: 217.0000 - recall: 0.7931 - precision: 0.8985 - binary accuracy: 0.9728 - val_loss: 0.0761 - val_tp: 226.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.8968 - val_binary accuracy: 0.9784\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0936 - tp: 852.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9054 - binary accuracy: 0.9750 - val_loss: 0.0750 - val_tp: 225.0000 - val_tn: 2577.0000 - val_fp: 25.0000 - val_fn: 37.0000 - val_recall: 0.8588 - val_precision: 0.9000 - val_binary accuracy: 0.9784\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0890 - tp: 863.0000 - tn: 10309.0000 - fp: 96.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.8999 - binary accuracy: 0.9754 - val_loss: 0.0753 - val_tp: 222.0000 - val_tn: 2578.0000 - val_fp: 24.0000 - val_fn: 40.0000 - val_recall: 0.8473 - val_precision: 0.9024 - val_binary accuracy: 0.9777\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0940 - tp: 835.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9047 - binary accuracy: 0.9736 - val_loss: 0.0751 - val_tp: 216.0000 - val_tn: 2584.0000 - val_fp: 18.0000 - val_fn: 46.0000 - val_recall: 0.8244 - val_precision: 0.9231 - val_binary accuracy: 0.9777\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0929 - tp: 829.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 220.0000 - recall: 0.7903 - precision: 0.9120 - binary accuracy: 0.9738 - val_loss: 0.0766 - val_tp: 224.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.8889 - val_binary accuracy: 0.9770\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0905 - tp: 852.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9035 - binary accuracy: 0.9749 - val_loss: 0.0758 - val_tp: 218.0000 - val_tn: 2583.0000 - val_fp: 19.0000 - val_fn: 44.0000 - val_recall: 0.8321 - val_precision: 0.9198 - val_binary accuracy: 0.9780\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0907 - tp: 841.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 208.0000 - recall: 0.8017 - precision: 0.9092 - binary accuracy: 0.9745 - val_loss: 0.0763 - val_tp: 214.0000 - val_tn: 2585.0000 - val_fp: 17.0000 - val_fn: 48.0000 - val_recall: 0.8168 - val_precision: 0.9264 - val_binary accuracy: 0.9773\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0926 - tp: 858.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9108 - binary accuracy: 0.9760 - val_loss: 0.0753 - val_tp: 217.0000 - val_tn: 2583.0000 - val_fp: 19.0000 - val_fn: 45.0000 - val_recall: 0.8282 - val_precision: 0.9195 - val_binary accuracy: 0.9777\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0906 - tp: 843.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 206.0000 - recall: 0.8036 - precision: 0.9163 - binary accuracy: 0.9753 - val_loss: 0.0745 - val_tp: 220.0000 - val_tn: 2578.0000 - val_fp: 24.0000 - val_fn: 42.0000 - val_recall: 0.8397 - val_precision: 0.9016 - val_binary accuracy: 0.9770\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0912 - tp: 853.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9133 - binary accuracy: 0.9758 - val_loss: 0.0749 - val_tp: 225.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 37.0000 - val_recall: 0.8588 - val_precision: 0.8964 - val_binary accuracy: 0.9780\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0897 - tp: 855.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9154 - binary accuracy: 0.9762 - val_loss: 0.0744 - val_tp: 224.0000 - val_tn: 2578.0000 - val_fp: 24.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.9032 - val_binary accuracy: 0.9784\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0922 - tp: 855.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9029 - binary accuracy: 0.9750 - val_loss: 0.0757 - val_tp: 224.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.8889 - val_binary accuracy: 0.9770\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0905 - tp: 863.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9123 - binary accuracy: 0.9765 - val_loss: 0.0745 - val_tp: 224.0000 - val_tn: 2577.0000 - val_fp: 25.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.8996 - val_binary accuracy: 0.9780\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0911 - tp: 853.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9017 - binary accuracy: 0.9748 - val_loss: 0.0823 - val_tp: 232.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8561 - val_binary accuracy: 0.9759\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0920 - tp: 845.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 204.0000 - recall: 0.8055 - precision: 0.9018 - binary accuracy: 0.9742 - val_loss: 0.0869 - val_tp: 234.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8298 - val_binary accuracy: 0.9735\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0893 - tp: 857.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9088 - binary accuracy: 0.9757 - val_loss: 0.0868 - val_tp: 235.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8304 - val_binary accuracy: 0.9738\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0918 - tp: 844.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 205.0000 - recall: 0.8046 - precision: 0.9124 - binary accuracy: 0.9750 - val_loss: 0.0800 - val_tp: 232.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8755 - val_binary accuracy: 0.9780\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0911 - tp: 852.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9054 - binary accuracy: 0.9750 - val_loss: 0.0893 - val_tp: 236.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8223 - val_binary accuracy: 0.9731\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0884 - tp: 866.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9097 - binary accuracy: 0.9765 - val_loss: 0.0865 - val_tp: 234.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8327 - val_binary accuracy: 0.9738\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0861 - tp: 871.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9178 - binary accuracy: 0.9776 - val_loss: 0.0835 - val_tp: 233.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8504 - val_binary accuracy: 0.9756\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0891 - tp: 844.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 205.0000 - recall: 0.8046 - precision: 0.9154 - binary accuracy: 0.9753 - val_loss: 0.0760 - val_tp: 229.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8980 - val_binary accuracy: 0.9794\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0894 - tp: 840.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 209.0000 - recall: 0.8008 - precision: 0.9081 - binary accuracy: 0.9743 - val_loss: 0.0813 - val_tp: 233.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8694 - val_binary accuracy: 0.9777\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0911 - tp: 864.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9028 - binary accuracy: 0.9757 - val_loss: 0.0851 - val_tp: 234.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8448 - val_binary accuracy: 0.9752\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0907 - tp: 846.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 203.0000 - recall: 0.8065 - precision: 0.9176 - binary accuracy: 0.9756 - val_loss: 0.0825 - val_tp: 233.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8504 - val_binary accuracy: 0.9756\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0940 - tp: 849.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 200.0000 - recall: 0.8093 - precision: 0.9051 - binary accuracy: 0.9748 - val_loss: 0.0922 - val_tp: 238.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8095 - val_binary accuracy: 0.9721\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0891 - tp: 859.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9023 - binary accuracy: 0.9753 - val_loss: 0.0896 - val_tp: 235.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8304 - val_binary accuracy: 0.9738\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0854 - tp: 857.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9117 - binary accuracy: 0.9760 - val_loss: 0.0826 - val_tp: 233.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8598 - val_binary accuracy: 0.9766\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0895 - tp: 856.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9116 - binary accuracy: 0.9759 - val_loss: 0.0836 - val_tp: 234.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8540 - val_binary accuracy: 0.9763\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0891 - tp: 867.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9126 - binary accuracy: 0.9769 - val_loss: 0.0790 - val_tp: 233.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8694 - val_binary accuracy: 0.9777\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0874 - tp: 857.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9069 - binary accuracy: 0.9756 - val_loss: 0.1021 - val_tp: 238.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7960 - val_binary accuracy: 0.9703\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0907 - tp: 847.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9011 - binary accuracy: 0.9742 - val_loss: 0.1118 - val_tp: 238.0000 - val_tn: 2519.0000 - val_fp: 83.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7414 - val_binary accuracy: 0.9626\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0878 - tp: 870.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9110 - binary accuracy: 0.9770 - val_loss: 0.0945 - val_tp: 238.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8095 - val_binary accuracy: 0.9721\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0864 - tp: 864.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9057 - binary accuracy: 0.9760 - val_loss: 0.1081 - val_tp: 239.0000 - val_tn: 2522.0000 - val_fp: 80.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7492 - val_binary accuracy: 0.9640\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0882 - tp: 869.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9033 - binary accuracy: 0.9762 - val_loss: 0.0990 - val_tp: 238.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8041 - val_binary accuracy: 0.9714\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0880 - tp: 865.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9153 - binary accuracy: 0.9770 - val_loss: 0.1061 - val_tp: 237.0000 - val_tn: 2531.0000 - val_fp: 71.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7695 - val_binary accuracy: 0.9665\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0864 - tp: 855.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9223 - binary accuracy: 0.9768 - val_loss: 0.1237 - val_tp: 242.0000 - val_tn: 2490.0000 - val_fp: 112.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.6836 - val_binary accuracy: 0.9539\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0875 - tp: 859.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9148 - binary accuracy: 0.9764 - val_loss: 0.1013 - val_tp: 237.0000 - val_tn: 2540.0000 - val_fp: 62.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7926 - val_binary accuracy: 0.9696\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0864 - tp: 857.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9265 - binary accuracy: 0.9773 - val_loss: 0.1111 - val_tp: 239.0000 - val_tn: 2517.0000 - val_fp: 85.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7377 - val_binary accuracy: 0.9623\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0900 - tp: 858.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9051 - binary accuracy: 0.9755 - val_loss: 0.0972 - val_tp: 238.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7907 - val_binary accuracy: 0.9696\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0866 - tp: 873.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9151 - binary accuracy: 0.9776 - val_loss: 0.0858 - val_tp: 235.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8275 - val_binary accuracy: 0.9735\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0873 - tp: 859.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9042 - binary accuracy: 0.9755 - val_loss: 0.0830 - val_tp: 233.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8473 - val_binary accuracy: 0.9752\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0872 - tp: 863.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9075 - binary accuracy: 0.9761 - val_loss: 0.0956 - val_tp: 238.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8123 - val_binary accuracy: 0.9724\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0876 - tp: 861.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9073 - binary accuracy: 0.9759 - val_loss: 0.1107 - val_tp: 238.0000 - val_tn: 2517.0000 - val_fp: 85.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7368 - val_binary accuracy: 0.9619\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0893 - tp: 851.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9082 - binary accuracy: 0.9752 - val_loss: 0.0872 - val_tp: 234.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8327 - val_binary accuracy: 0.9738\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0922 - tp: 852.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9016 - binary accuracy: 0.9747 - val_loss: 0.0822 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0864 - tp: 858.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9089 - binary accuracy: 0.9758 - val_loss: 0.0801 - val_tp: 233.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8662 - val_binary accuracy: 0.9773\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0885 - tp: 866.0000 - tn: 10300.0000 - fp: 105.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.8919 - binary accuracy: 0.9749 - val_loss: 0.0915 - val_tp: 237.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8089 - val_binary accuracy: 0.9717\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0883 - tp: 862.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9102 - binary accuracy: 0.9763 - val_loss: 0.0952 - val_tp: 237.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7980 - val_binary accuracy: 0.9703\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0874 - tp: 861.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9101 - binary accuracy: 0.9762 - val_loss: 0.1013 - val_tp: 238.0000 - val_tn: 2531.0000 - val_fp: 71.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7702 - val_binary accuracy: 0.9668\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0915 - tp: 860.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9043 - binary accuracy: 0.9756 - val_loss: 0.0850 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0897 - tp: 865.0000 - tn: 10301.0000 - fp: 104.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.8927 - binary accuracy: 0.9749 - val_loss: 0.0913 - val_tp: 238.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8151 - val_binary accuracy: 0.9728\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0878 - tp: 851.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9151 - binary accuracy: 0.9758 - val_loss: 0.0859 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0878 - tp: 860.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9110 - binary accuracy: 0.9762 - val_loss: 0.1008 - val_tp: 238.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7628 - val_binary accuracy: 0.9658\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0844 - tp: 857.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9117 - binary accuracy: 0.9760 - val_loss: 0.1112 - val_tp: 239.0000 - val_tn: 2513.0000 - val_fp: 89.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7287 - val_binary accuracy: 0.9609\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0930 - tp: 859.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9023 - binary accuracy: 0.9753 - val_loss: 0.1018 - val_tp: 238.0000 - val_tn: 2536.0000 - val_fp: 66.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7829 - val_binary accuracy: 0.9686\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0906 - tp: 847.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9078 - binary accuracy: 0.9749 - val_loss: 0.1209 - val_tp: 240.0000 - val_tn: 2503.0000 - val_fp: 99.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7080 - val_binary accuracy: 0.9578\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0866 - tp: 850.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9120 - binary accuracy: 0.9755 - val_loss: 0.1140 - val_tp: 240.0000 - val_tn: 2518.0000 - val_fp: 84.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7407 - val_binary accuracy: 0.9630\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0872 - tp: 850.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9072 - binary accuracy: 0.9750 - val_loss: 0.0987 - val_tp: 238.0000 - val_tn: 2540.0000 - val_fp: 62.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7933 - val_binary accuracy: 0.9700\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0888 - tp: 867.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9117 - binary accuracy: 0.9768 - val_loss: 0.0789 - val_tp: 232.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8722 - val_binary accuracy: 0.9777\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0876 - tp: 848.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9177 - binary accuracy: 0.9758 - val_loss: 0.0841 - val_tp: 234.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8478 - val_binary accuracy: 0.9756\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0856 - tp: 868.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9127 - binary accuracy: 0.9770 - val_loss: 0.0867 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0881 - tp: 854.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9104 - binary accuracy: 0.9756 - val_loss: 0.0803 - val_tp: 232.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8657 - val_binary accuracy: 0.9770\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0858 - tp: 850.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9189 - binary accuracy: 0.9761 - val_loss: 0.0970 - val_tp: 238.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8068 - val_binary accuracy: 0.9717\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0888 - tp: 874.0000 - tn: 10310.0000 - fp: 95.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9020 - binary accuracy: 0.9764 - val_loss: 0.0997 - val_tp: 238.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7907 - val_binary accuracy: 0.9696\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0888 - tp: 863.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9113 - binary accuracy: 0.9764 - val_loss: 0.1050 - val_tp: 238.0000 - val_tn: 2533.0000 - val_fp: 69.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7752 - val_binary accuracy: 0.9675\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0852 - tp: 860.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9149 - binary accuracy: 0.9765 - val_loss: 0.1158 - val_tp: 240.0000 - val_tn: 2508.0000 - val_fp: 94.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7186 - val_binary accuracy: 0.9595\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0861 - tp: 862.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9026 - binary accuracy: 0.9756 - val_loss: 0.0953 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0914 - tp: 862.0000 - tn: 10306.0000 - fp: 99.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.8970 - binary accuracy: 0.9750 - val_loss: 0.1006 - val_tp: 238.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7778 - val_binary accuracy: 0.9679\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0879 - tp: 860.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9081 - binary accuracy: 0.9759 - val_loss: 0.1074 - val_tp: 238.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7604 - val_binary accuracy: 0.9654\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0851 - tp: 869.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9109 - binary accuracy: 0.9769 - val_loss: 0.1226 - val_tp: 240.0000 - val_tn: 2494.0000 - val_fp: 108.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.6897 - val_binary accuracy: 0.9546\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.0890 - tp: 864.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9124 - binary accuracy: 0.9766 - val_loss: 0.1087 - val_tp: 239.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7636 - val_binary accuracy: 0.9661\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0849 - tp: 862.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9219 - binary accuracy: 0.9773 - val_loss: 0.1092 - val_tp: 239.0000 - val_tn: 2525.0000 - val_fp: 77.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7563 - val_binary accuracy: 0.9651\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0856 - tp: 870.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9110 - binary accuracy: 0.9770 - val_loss: 0.1181 - val_tp: 240.0000 - val_tn: 2511.0000 - val_fp: 91.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7251 - val_binary accuracy: 0.9605\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0884 - tp: 850.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9229 - binary accuracy: 0.9764 - val_loss: 0.1064 - val_tp: 238.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7604 - val_binary accuracy: 0.9654\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.0846 - tp: 855.0000 - tn: 10342.0000 - fp: 63.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9314 - binary accuracy: 0.9776 - val_loss: 0.0968 - val_tp: 238.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8041 - val_binary accuracy: 0.9714\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0845 - tp: 866.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9078 - binary accuracy: 0.9763 - val_loss: 0.0985 - val_tp: 238.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7987 - val_binary accuracy: 0.9707\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0845 - tp: 874.0000 - tn: 10308.0000 - fp: 97.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9001 - binary accuracy: 0.9763 - val_loss: 0.1126 - val_tp: 238.0000 - val_tn: 2515.0000 - val_fp: 87.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7323 - val_binary accuracy: 0.9612\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0872 - tp: 852.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9122 - binary accuracy: 0.9756 - val_loss: 0.1125 - val_tp: 239.0000 - val_tn: 2524.0000 - val_fp: 78.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7539 - val_binary accuracy: 0.9647\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0896 - tp: 874.0000 - tn: 10311.0000 - fp: 94.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9029 - binary accuracy: 0.9765 - val_loss: 0.1229 - val_tp: 240.0000 - val_tn: 2511.0000 - val_fp: 91.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7251 - val_binary accuracy: 0.9605\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0837 - tp: 865.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9096 - binary accuracy: 0.9764 - val_loss: 0.1434 - val_tp: 243.0000 - val_tn: 2463.0000 - val_fp: 139.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.6361 - val_binary accuracy: 0.9448\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0889 - tp: 854.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9075 - binary accuracy: 0.9754 - val_loss: 0.1006 - val_tp: 238.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7778 - val_binary accuracy: 0.9679\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0858 - tp: 868.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9166 - binary accuracy: 0.9773 - val_loss: 0.0833 - val_tp: 233.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8504 - val_binary accuracy: 0.9756\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0851 - tp: 869.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9206 - binary accuracy: 0.9777 - val_loss: 0.0940 - val_tp: 238.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8123 - val_binary accuracy: 0.9724\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0845 - tp: 871.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9101 - binary accuracy: 0.9770 - val_loss: 0.0895 - val_tp: 235.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8246 - val_binary accuracy: 0.9731\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0837 - tp: 864.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9191 - binary accuracy: 0.9772 - val_loss: 0.0819 - val_tp: 232.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8657 - val_binary accuracy: 0.9770\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0862 - tp: 858.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9108 - binary accuracy: 0.9760 - val_loss: 0.0854 - val_tp: 234.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8478 - val_binary accuracy: 0.9756\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0835 - tp: 862.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9074 - binary accuracy: 0.9760 - val_loss: 0.0813 - val_tp: 233.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8566 - val_binary accuracy: 0.9763\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0866 - tp: 862.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9200 - binary accuracy: 0.9771 - val_loss: 0.0847 - val_tp: 234.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8509 - val_binary accuracy: 0.9759\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0854 - tp: 867.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9041 - binary accuracy: 0.9761 - val_loss: 0.0966 - val_tp: 238.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8123 - val_binary accuracy: 0.9724\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0884 - tp: 851.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9111 - binary accuracy: 0.9755 - val_loss: 0.0951 - val_tp: 238.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8041 - val_binary accuracy: 0.9714\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0852 - tp: 854.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9037 - binary accuracy: 0.9750 - val_loss: 0.1138 - val_tp: 240.0000 - val_tn: 2512.0000 - val_fp: 90.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7273 - val_binary accuracy: 0.9609\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0864 - tp: 871.0000 - tn: 10311.0000 - fp: 94.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9026 - binary accuracy: 0.9763 - val_loss: 0.1175 - val_tp: 240.0000 - val_tn: 2505.0000 - val_fp: 97.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7122 - val_binary accuracy: 0.9584\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0863 - tp: 885.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 164.0000 - recall: 0.8437 - precision: 0.9058 - binary accuracy: 0.9776 - val_loss: 0.1069 - val_tp: 238.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7628 - val_binary accuracy: 0.9658\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0847 - tp: 877.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9116 - binary accuracy: 0.9776 - val_loss: 0.1038 - val_tp: 239.0000 - val_tn: 2535.0000 - val_fp: 67.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7810 - val_binary accuracy: 0.9686\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0853 - tp: 867.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9223 - binary accuracy: 0.9777 - val_loss: 0.0970 - val_tp: 238.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7960 - val_binary accuracy: 0.9703\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0879 - tp: 861.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9169 - binary accuracy: 0.9768 - val_loss: 0.0941 - val_tp: 237.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8144 - val_binary accuracy: 0.9724\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0825 - tp: 874.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9133 - binary accuracy: 0.9775 - val_loss: 0.0929 - val_tp: 237.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8144 - val_binary accuracy: 0.9724\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0843 - tp: 864.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9076 - binary accuracy: 0.9762 - val_loss: 0.1115 - val_tp: 238.0000 - val_tn: 2513.0000 - val_fp: 89.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7278 - val_binary accuracy: 0.9605\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0842 - tp: 867.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9136 - binary accuracy: 0.9770 - val_loss: 0.1148 - val_tp: 238.0000 - val_tn: 2507.0000 - val_fp: 95.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7147 - val_binary accuracy: 0.9584\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0854 - tp: 864.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9260 - binary accuracy: 0.9778 - val_loss: 0.1208 - val_tp: 240.0000 - val_tn: 2504.0000 - val_fp: 98.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7101 - val_binary accuracy: 0.9581\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0879 - tp: 865.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9144 - binary accuracy: 0.9769 - val_loss: 0.0974 - val_tp: 238.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7987 - val_binary accuracy: 0.9707\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0820 - tp: 881.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9101 - binary accuracy: 0.9777 - val_loss: 0.0997 - val_tp: 238.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7907 - val_binary accuracy: 0.9696\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0867 - tp: 870.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9072 - binary accuracy: 0.9766 - val_loss: 0.1095 - val_tp: 239.0000 - val_tn: 2521.0000 - val_fp: 81.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7469 - val_binary accuracy: 0.9637\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0831 - tp: 863.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9240 - binary accuracy: 0.9776 - val_loss: 0.1085 - val_tp: 239.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7636 - val_binary accuracy: 0.9661\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0836 - tp: 866.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9145 - binary accuracy: 0.9770 - val_loss: 0.1095 - val_tp: 238.0000 - val_tn: 2525.0000 - val_fp: 77.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7556 - val_binary accuracy: 0.9647\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0886 - tp: 863.0000 - tn: 10299.0000 - fp: 106.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.8906 - binary accuracy: 0.9745 - val_loss: 0.1078 - val_tp: 238.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7628 - val_binary accuracy: 0.9658\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0870 - tp: 858.0000 - tn: 10304.0000 - fp: 101.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.8947 - binary accuracy: 0.9745 - val_loss: 0.0910 - val_tp: 235.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8275 - val_binary accuracy: 0.9735\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0841 - tp: 868.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9137 - binary accuracy: 0.9770 - val_loss: 0.0908 - val_tp: 235.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8246 - val_binary accuracy: 0.9731\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0847 - tp: 871.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9092 - binary accuracy: 0.9769 - val_loss: 0.0881 - val_tp: 235.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8304 - val_binary accuracy: 0.9738\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0842 - tp: 874.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9114 - binary accuracy: 0.9773 - val_loss: 0.0929 - val_tp: 237.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8172 - val_binary accuracy: 0.9728\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0842 - tp: 868.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9166 - binary accuracy: 0.9773 - val_loss: 0.0953 - val_tp: 237.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8116 - val_binary accuracy: 0.9721\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0828 - tp: 867.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9098 - binary accuracy: 0.9766 - val_loss: 0.0946 - val_tp: 235.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8048 - val_binary accuracy: 0.9707\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0850 - tp: 861.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9035 - binary accuracy: 0.9756 - val_loss: 0.0895 - val_tp: 235.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8304 - val_binary accuracy: 0.9738\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0832 - tp: 867.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9098 - binary accuracy: 0.9766 - val_loss: 0.0991 - val_tp: 238.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7881 - val_binary accuracy: 0.9693\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0816 - tp: 855.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9115 - binary accuracy: 0.9758 - val_loss: 0.0957 - val_tp: 238.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8068 - val_binary accuracy: 0.9717\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0841 - tp: 859.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9129 - binary accuracy: 0.9763 - val_loss: 0.1074 - val_tp: 238.0000 - val_tn: 2529.0000 - val_fp: 73.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7653 - val_binary accuracy: 0.9661\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0858 - tp: 868.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9042 - binary accuracy: 0.9762 - val_loss: 0.0984 - val_tp: 238.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7960 - val_binary accuracy: 0.9703\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0815 - tp: 881.0000 - tn: 10309.0000 - fp: 96.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9017 - binary accuracy: 0.9770 - val_loss: 0.0961 - val_tp: 235.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8020 - val_binary accuracy: 0.9703\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0841 - tp: 868.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9156 - binary accuracy: 0.9772 - val_loss: 0.0938 - val_tp: 238.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8151 - val_binary accuracy: 0.9728\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0855 - tp: 870.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9110 - binary accuracy: 0.9770 - val_loss: 0.0931 - val_tp: 235.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8160 - val_binary accuracy: 0.9721\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0836 - tp: 872.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9083 - binary accuracy: 0.9769 - val_loss: 0.0939 - val_tp: 238.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8123 - val_binary accuracy: 0.9724\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0827 - tp: 873.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9113 - binary accuracy: 0.9772 - val_loss: 0.0840 - val_tp: 233.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8504 - val_binary accuracy: 0.9756\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0855 - tp: 869.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9080 - binary accuracy: 0.9766 - val_loss: 0.0965 - val_tp: 238.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8013 - val_binary accuracy: 0.9710\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0867 - tp: 877.0000 - tn: 10311.0000 - fp: 94.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9032 - binary accuracy: 0.9768 - val_loss: 0.1074 - val_tp: 239.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7636 - val_binary accuracy: 0.9661\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0863 - tp: 860.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9218 - binary accuracy: 0.9771 - val_loss: 0.0899 - val_tp: 234.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8357 - val_binary accuracy: 0.9742\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0864 - tp: 869.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9186 - binary accuracy: 0.9776 - val_loss: 0.0862 - val_tp: 235.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8423 - val_binary accuracy: 0.9752\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0802 - tp: 873.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9141 - binary accuracy: 0.9775 - val_loss: 0.0879 - val_tp: 234.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8327 - val_binary accuracy: 0.9738\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0842 - tp: 872.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9179 - binary accuracy: 0.9777 - val_loss: 0.0943 - val_tp: 237.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8061 - val_binary accuracy: 0.9714\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0846 - tp: 883.0000 - tn: 10308.0000 - fp: 97.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9010 - binary accuracy: 0.9770 - val_loss: 0.0836 - val_tp: 233.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8442 - val_binary accuracy: 0.9749\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0831 - tp: 873.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9151 - binary accuracy: 0.9776 - val_loss: 0.0867 - val_tp: 235.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8246 - val_binary accuracy: 0.9731\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0806 - tp: 888.0000 - tn: 10311.0000 - fp: 94.0000 - fn: 161.0000 - recall: 0.8465 - precision: 0.9043 - binary accuracy: 0.9777 - val_loss: 0.0909 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0840 - tp: 867.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9214 - binary accuracy: 0.9776 - val_loss: 0.0744 - val_tp: 224.0000 - val_tn: 2578.0000 - val_fp: 24.0000 - val_fn: 38.0000 - val_recall: 0.8550 - val_precision: 0.9032 - val_binary accuracy: 0.9784\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0837 - tp: 867.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9243 - binary accuracy: 0.9779 - val_loss: 0.0805 - val_tp: 233.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8566 - val_binary accuracy: 0.9763\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0852 - tp: 868.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9118 - binary accuracy: 0.9769 - val_loss: 0.1085 - val_tp: 239.0000 - val_tn: 2520.0000 - val_fp: 82.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7445 - val_binary accuracy: 0.9633\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0829 - tp: 883.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9169 - binary accuracy: 0.9785 - val_loss: 0.1073 - val_tp: 239.0000 - val_tn: 2532.0000 - val_fp: 70.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7735 - val_binary accuracy: 0.9675\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0848 - tp: 852.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9171 - binary accuracy: 0.9761 - val_loss: 0.0957 - val_tp: 236.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8027 - val_binary accuracy: 0.9707\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0836 - tp: 875.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9086 - binary accuracy: 0.9771 - val_loss: 0.0963 - val_tp: 238.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8123 - val_binary accuracy: 0.9724\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0846 - tp: 874.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9171 - binary accuracy: 0.9778 - val_loss: 0.0871 - val_tp: 234.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8509 - val_binary accuracy: 0.9759\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0825 - tp: 873.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9132 - binary accuracy: 0.9774 - val_loss: 0.0946 - val_tp: 238.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8041 - val_binary accuracy: 0.9714\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0825 - tp: 879.0000 - tn: 10308.0000 - fp: 97.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9006 - binary accuracy: 0.9767 - val_loss: 0.0912 - val_tp: 235.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8020 - val_binary accuracy: 0.9703\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0845 - tp: 872.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9102 - binary accuracy: 0.9770 - val_loss: 0.0936 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0831 - tp: 886.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 163.0000 - recall: 0.8446 - precision: 0.9078 - binary accuracy: 0.9779 - val_loss: 0.0884 - val_tp: 235.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8304 - val_binary accuracy: 0.9738\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0838 - tp: 865.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9183 - binary accuracy: 0.9772 - val_loss: 0.0932 - val_tp: 236.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8000 - val_binary accuracy: 0.9703\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0840 - tp: 876.0000 - tn: 10308.0000 - fp: 97.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9003 - binary accuracy: 0.9764 - val_loss: 0.0822 - val_tp: 234.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8571 - val_binary accuracy: 0.9766\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0832 - tp: 865.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9163 - binary accuracy: 0.9770 - val_loss: 0.0790 - val_tp: 231.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8750 - val_binary accuracy: 0.9777\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0823 - tp: 873.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9103 - binary accuracy: 0.9771 - val_loss: 0.0981 - val_tp: 237.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8007 - val_binary accuracy: 0.9707\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0845 - tp: 874.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9104 - binary accuracy: 0.9772 - val_loss: 0.1034 - val_tp: 237.0000 - val_tn: 2537.0000 - val_fp: 65.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7848 - val_binary accuracy: 0.9686\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0831 - tp: 871.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9149 - binary accuracy: 0.9774 - val_loss: 0.0994 - val_tp: 236.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7946 - val_binary accuracy: 0.9696\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0842 - tp: 874.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9142 - binary accuracy: 0.9776 - val_loss: 0.1042 - val_tp: 239.0000 - val_tn: 2533.0000 - val_fp: 69.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7760 - val_binary accuracy: 0.9679\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0832 - tp: 878.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9042 - binary accuracy: 0.9770 - val_loss: 0.1105 - val_tp: 240.0000 - val_tn: 2524.0000 - val_fp: 78.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7547 - val_binary accuracy: 0.9651\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0845 - tp: 859.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9138 - binary accuracy: 0.9763 - val_loss: 0.1037 - val_tp: 238.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7628 - val_binary accuracy: 0.9658\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0818 - tp: 869.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9196 - binary accuracy: 0.9776 - val_loss: 0.0860 - val_tp: 234.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8478 - val_binary accuracy: 0.9756\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0844 - tp: 868.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9089 - binary accuracy: 0.9766 - val_loss: 0.1089 - val_tp: 240.0000 - val_tn: 2519.0000 - val_fp: 83.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7430 - val_binary accuracy: 0.9633\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0855 - tp: 880.0000 - tn: 10299.0000 - fp: 106.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.8925 - binary accuracy: 0.9760 - val_loss: 0.1277 - val_tp: 241.0000 - val_tn: 2484.0000 - val_fp: 118.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.6713 - val_binary accuracy: 0.9515\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0823 - tp: 878.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9080 - binary accuracy: 0.9773 - val_loss: 0.1018 - val_tp: 238.0000 - val_tn: 2536.0000 - val_fp: 66.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7829 - val_binary accuracy: 0.9686\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0831 - tp: 880.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9195 - binary accuracy: 0.9785 - val_loss: 0.1011 - val_tp: 237.0000 - val_tn: 2537.0000 - val_fp: 65.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7848 - val_binary accuracy: 0.9686\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0850 - tp: 870.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9139 - binary accuracy: 0.9772 - val_loss: 0.1097 - val_tp: 239.0000 - val_tn: 2531.0000 - val_fp: 71.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7710 - val_binary accuracy: 0.9672\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0840 - tp: 871.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9054 - binary accuracy: 0.9765 - val_loss: 0.1111 - val_tp: 239.0000 - val_tn: 2519.0000 - val_fp: 83.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7422 - val_binary accuracy: 0.9630\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0854 - tp: 878.0000 - tn: 10307.0000 - fp: 98.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.8996 - binary accuracy: 0.9765 - val_loss: 0.0919 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0841 - tp: 863.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9046 - binary accuracy: 0.9758 - val_loss: 0.0910 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0837 - tp: 874.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9142 - binary accuracy: 0.9776 - val_loss: 0.0858 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0835 - tp: 865.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9163 - binary accuracy: 0.9770 - val_loss: 0.0897 - val_tp: 235.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8217 - val_binary accuracy: 0.9728\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0830 - tp: 874.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9104 - binary accuracy: 0.9772 - val_loss: 0.0988 - val_tp: 237.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7874 - val_binary accuracy: 0.9689\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0832 - tp: 871.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9092 - binary accuracy: 0.9769 - val_loss: 0.1001 - val_tp: 238.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7907 - val_binary accuracy: 0.9696\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0810 - tp: 880.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9157 - binary accuracy: 0.9782 - val_loss: 0.1370 - val_tp: 241.0000 - val_tn: 2480.0000 - val_fp: 122.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.6639 - val_binary accuracy: 0.9501\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0862 - tp: 880.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9082 - binary accuracy: 0.9775 - val_loss: 0.2264 - val_tp: 247.0000 - val_tn: 2293.0000 - val_fp: 309.0000 - val_fn: 15.0000 - val_recall: 0.9427 - val_precision: 0.4442 - val_binary accuracy: 0.8869\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0867 - tp: 868.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9032 - binary accuracy: 0.9761 - val_loss: 0.1762 - val_tp: 245.0000 - val_tn: 2408.0000 - val_fp: 194.0000 - val_fn: 17.0000 - val_recall: 0.9351 - val_precision: 0.5581 - val_binary accuracy: 0.9263\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0824 - tp: 872.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9189 - binary accuracy: 0.9778 - val_loss: 0.1655 - val_tp: 245.0000 - val_tn: 2419.0000 - val_fp: 183.0000 - val_fn: 17.0000 - val_recall: 0.9351 - val_precision: 0.5724 - val_binary accuracy: 0.9302\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0853 - tp: 872.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9160 - binary accuracy: 0.9776 - val_loss: 0.1089 - val_tp: 240.0000 - val_tn: 2531.0000 - val_fp: 71.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7717 - val_binary accuracy: 0.9675\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0828 - tp: 863.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9200 - binary accuracy: 0.9772 - val_loss: 0.0930 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0836 - tp: 882.0000 - tn: 10305.0000 - fp: 100.0000 - fn: 167.0000 - recall: 0.8408 - precision: 0.8982 - binary accuracy: 0.9767 - val_loss: 0.0929 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0812 - tp: 871.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9197 - binary accuracy: 0.9778 - val_loss: 0.0758 - val_tp: 229.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8876 - val_binary accuracy: 0.9784\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0821 - tp: 868.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9175 - binary accuracy: 0.9774 - val_loss: 0.0891 - val_tp: 236.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8223 - val_binary accuracy: 0.9731\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0855 - tp: 873.0000 - tn: 10310.0000 - fp: 95.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9019 - binary accuracy: 0.9763 - val_loss: 0.0930 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0843 - tp: 882.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 167.0000 - recall: 0.8408 - precision: 0.9065 - binary accuracy: 0.9775 - val_loss: 0.1003 - val_tp: 237.0000 - val_tn: 2537.0000 - val_fp: 65.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7848 - val_binary accuracy: 0.9686\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0820 - tp: 868.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9214 - binary accuracy: 0.9777 - val_loss: 0.0947 - val_tp: 238.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8123 - val_binary accuracy: 0.9724\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0816 - tp: 868.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9224 - binary accuracy: 0.9778 - val_loss: 0.1100 - val_tp: 239.0000 - val_tn: 2517.0000 - val_fp: 85.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7377 - val_binary accuracy: 0.9623\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0825 - tp: 881.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9139 - binary accuracy: 0.9781 - val_loss: 0.0887 - val_tp: 235.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8275 - val_binary accuracy: 0.9735\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0857 - tp: 862.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9141 - binary accuracy: 0.9766 - val_loss: 0.0953 - val_tp: 237.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8007 - val_binary accuracy: 0.9707\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0814 - tp: 873.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9161 - binary accuracy: 0.9776 - val_loss: 0.0977 - val_tp: 237.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7953 - val_binary accuracy: 0.9700\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0814 - tp: 877.0000 - tn: 10310.0000 - fp: 95.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9023 - binary accuracy: 0.9767 - val_loss: 0.1033 - val_tp: 239.0000 - val_tn: 2535.0000 - val_fp: 67.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7810 - val_binary accuracy: 0.9686\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0833 - tp: 876.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9192 - binary accuracy: 0.9782 - val_loss: 0.0938 - val_tp: 237.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7980 - val_binary accuracy: 0.9703\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0820 - tp: 874.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9229 - binary accuracy: 0.9783 - val_loss: 0.0877 - val_tp: 235.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8393 - val_binary accuracy: 0.9749\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0822 - tp: 875.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9201 - binary accuracy: 0.9782 - val_loss: 0.0852 - val_tp: 234.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8478 - val_binary accuracy: 0.9756\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0819 - tp: 873.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9161 - binary accuracy: 0.9776 - val_loss: 0.0868 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0829 - tp: 890.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 159.0000 - recall: 0.8484 - precision: 0.9110 - binary accuracy: 0.9785 - val_loss: 0.0886 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0840 - tp: 869.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9090 - binary accuracy: 0.9767 - val_loss: 0.0870 - val_tp: 235.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8160 - val_binary accuracy: 0.9721\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0837 - tp: 874.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9085 - binary accuracy: 0.9770 - val_loss: 0.0883 - val_tp: 235.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8304 - val_binary accuracy: 0.9738\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0820 - tp: 876.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9202 - binary accuracy: 0.9783 - val_loss: 0.0957 - val_tp: 236.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8000 - val_binary accuracy: 0.9703\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0841 - tp: 867.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9050 - binary accuracy: 0.9762 - val_loss: 0.0922 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0816 - tp: 881.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9054 - binary accuracy: 0.9773 - val_loss: 0.0829 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0813 - tp: 866.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9193 - binary accuracy: 0.9774 - val_loss: 0.0830 - val_tp: 234.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8509 - val_binary accuracy: 0.9759\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0817 - tp: 880.0000 - tn: 10306.0000 - fp: 99.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.8989 - binary accuracy: 0.9766 - val_loss: 0.0937 - val_tp: 237.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7980 - val_binary accuracy: 0.9703\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0854 - tp: 868.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9118 - binary accuracy: 0.9769 - val_loss: 0.0809 - val_tp: 232.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8689 - val_binary accuracy: 0.9773\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0823 - tp: 876.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9280 - binary accuracy: 0.9790 - val_loss: 0.0980 - val_tp: 237.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7900 - val_binary accuracy: 0.9693\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0847 - tp: 888.0000 - tn: 10306.0000 - fp: 99.0000 - fn: 161.0000 - recall: 0.8465 - precision: 0.8997 - binary accuracy: 0.9773 - val_loss: 0.0859 - val_tp: 236.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8339 - val_binary accuracy: 0.9745\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0826 - tp: 874.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9152 - binary accuracy: 0.9776 - val_loss: 0.0875 - val_tp: 235.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8304 - val_binary accuracy: 0.9738\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0868 - tp: 865.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9096 - binary accuracy: 0.9764 - val_loss: 0.0962 - val_tp: 236.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7893 - val_binary accuracy: 0.9689\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0824 - tp: 884.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 165.0000 - recall: 0.8427 - precision: 0.9132 - binary accuracy: 0.9783 - val_loss: 0.0844 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0807 - tp: 876.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9154 - binary accuracy: 0.9778 - val_loss: 0.0919 - val_tp: 235.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8076 - val_binary accuracy: 0.9710\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0791 - tp: 874.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9133 - binary accuracy: 0.9775 - val_loss: 0.1084 - val_tp: 239.0000 - val_tn: 2529.0000 - val_fp: 73.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7660 - val_binary accuracy: 0.9665\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0838 - tp: 867.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9155 - binary accuracy: 0.9771 - val_loss: 0.1152 - val_tp: 239.0000 - val_tn: 2522.0000 - val_fp: 80.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7492 - val_binary accuracy: 0.9640\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0831 - tp: 885.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 164.0000 - recall: 0.8437 - precision: 0.9161 - binary accuracy: 0.9786 - val_loss: 0.1069 - val_tp: 238.0000 - val_tn: 2537.0000 - val_fp: 65.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7855 - val_binary accuracy: 0.9689\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0836 - tp: 874.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9133 - binary accuracy: 0.9775 - val_loss: 0.1249 - val_tp: 241.0000 - val_tn: 2503.0000 - val_fp: 99.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7088 - val_binary accuracy: 0.9581\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0830 - tp: 888.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 161.0000 - recall: 0.8465 - precision: 0.9080 - binary accuracy: 0.9781 - val_loss: 0.1135 - val_tp: 239.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7611 - val_binary accuracy: 0.9658\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0844 - tp: 882.0000 - tn: 10311.0000 - fp: 94.0000 - fn: 167.0000 - recall: 0.8408 - precision: 0.9037 - binary accuracy: 0.9772 - val_loss: 0.1267 - val_tp: 242.0000 - val_tn: 2480.0000 - val_fp: 122.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.6648 - val_binary accuracy: 0.9504\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0806 - tp: 873.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9075 - binary accuracy: 0.9769 - val_loss: 0.1011 - val_tp: 238.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7778 - val_binary accuracy: 0.9679\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0798 - tp: 886.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 163.0000 - recall: 0.8446 - precision: 0.9220 - binary accuracy: 0.9792 - val_loss: 0.1023 - val_tp: 238.0000 - val_tn: 2536.0000 - val_fp: 66.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7829 - val_binary accuracy: 0.9686\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0846 - tp: 872.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9160 - binary accuracy: 0.9776 - val_loss: 0.1171 - val_tp: 241.0000 - val_tn: 2504.0000 - val_fp: 98.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7109 - val_binary accuracy: 0.9584\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0794 - tp: 889.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 160.0000 - recall: 0.8475 - precision: 0.9109 - binary accuracy: 0.9784 - val_loss: 0.1210 - val_tp: 241.0000 - val_tn: 2500.0000 - val_fp: 102.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7026 - val_binary accuracy: 0.9571\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0831 - tp: 871.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9120 - binary accuracy: 0.9771 - val_loss: 0.0965 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0802 - tp: 878.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9098 - binary accuracy: 0.9775 - val_loss: 0.0963 - val_tp: 236.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8000 - val_binary accuracy: 0.9703\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0849 - tp: 877.0000 - tn: 10309.0000 - fp: 96.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9013 - binary accuracy: 0.9766 - val_loss: 0.1050 - val_tp: 240.0000 - val_tn: 2523.0000 - val_fp: 79.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7524 - val_binary accuracy: 0.9647\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0827 - tp: 877.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9126 - binary accuracy: 0.9776 - val_loss: 0.0987 - val_tp: 237.0000 - val_tn: 2540.0000 - val_fp: 62.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7926 - val_binary accuracy: 0.9696\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0811 - tp: 886.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 163.0000 - recall: 0.8446 - precision: 0.9172 - binary accuracy: 0.9788 - val_loss: 0.0978 - val_tp: 237.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7874 - val_binary accuracy: 0.9689\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0823 - tp: 864.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9076 - binary accuracy: 0.9762 - val_loss: 0.0991 - val_tp: 236.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7763 - val_binary accuracy: 0.9672\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0827 - tp: 873.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9228 - binary accuracy: 0.9783 - val_loss: 0.0826 - val_tp: 235.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8423 - val_binary accuracy: 0.9752\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0838 - tp: 868.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9118 - binary accuracy: 0.9769 - val_loss: 0.0979 - val_tp: 237.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7874 - val_binary accuracy: 0.9689\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0831 - tp: 872.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9160 - binary accuracy: 0.9776 - val_loss: 0.0912 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0826 - tp: 872.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9169 - binary accuracy: 0.9776 - val_loss: 0.0775 - val_tp: 230.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 32.0000 - val_recall: 0.8779 - val_precision: 0.8880 - val_binary accuracy: 0.9787\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0821 - tp: 866.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9116 - binary accuracy: 0.9767 - val_loss: 0.0917 - val_tp: 238.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8041 - val_binary accuracy: 0.9714\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0812 - tp: 884.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 165.0000 - recall: 0.8427 - precision: 0.9067 - binary accuracy: 0.9776 - val_loss: 0.1015 - val_tp: 239.0000 - val_tn: 2522.0000 - val_fp: 80.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7492 - val_binary accuracy: 0.9640\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0830 - tp: 878.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9108 - binary accuracy: 0.9776 - val_loss: 0.0810 - val_tp: 233.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8792 - val_binary accuracy: 0.9787\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0786 - tp: 882.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 167.0000 - recall: 0.8408 - precision: 0.9187 - binary accuracy: 0.9786 - val_loss: 0.1091 - val_tp: 239.0000 - val_tn: 2523.0000 - val_fp: 79.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7516 - val_binary accuracy: 0.9644\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0843 - tp: 884.0000 - tn: 10305.0000 - fp: 100.0000 - fn: 165.0000 - recall: 0.8427 - precision: 0.8984 - binary accuracy: 0.9769 - val_loss: 0.1126 - val_tp: 240.0000 - val_tn: 2518.0000 - val_fp: 84.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7407 - val_binary accuracy: 0.9630\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0821 - tp: 881.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9148 - binary accuracy: 0.9782 - val_loss: 0.0925 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0825 - tp: 877.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9154 - binary accuracy: 0.9779 - val_loss: 0.1147 - val_tp: 239.0000 - val_tn: 2520.0000 - val_fp: 82.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7445 - val_binary accuracy: 0.9633\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0800 - tp: 885.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 164.0000 - recall: 0.8437 - precision: 0.9180 - binary accuracy: 0.9788 - val_loss: 0.1029 - val_tp: 237.0000 - val_tn: 2540.0000 - val_fp: 62.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7926 - val_binary accuracy: 0.9696\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0840 - tp: 867.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9146 - binary accuracy: 0.9770 - val_loss: 0.0940 - val_tp: 237.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8061 - val_binary accuracy: 0.9714\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0833 - tp: 874.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9171 - binary accuracy: 0.9778 - val_loss: 0.1178 - val_tp: 240.0000 - val_tn: 2501.0000 - val_fp: 101.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7038 - val_binary accuracy: 0.9571\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0829 - tp: 863.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9152 - binary accuracy: 0.9768 - val_loss: 0.0914 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0829 - tp: 873.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9122 - binary accuracy: 0.9773 - val_loss: 0.0948 - val_tp: 236.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7946 - val_binary accuracy: 0.9696\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0811 - tp: 876.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9097 - binary accuracy: 0.9773 - val_loss: 0.0826 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0840 - tp: 862.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9180 - binary accuracy: 0.9770 - val_loss: 0.0793 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0808 - tp: 873.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9199 - binary accuracy: 0.9780 - val_loss: 0.0912 - val_tp: 237.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8116 - val_binary accuracy: 0.9721\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0784 - tp: 880.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9119 - binary accuracy: 0.9778 - val_loss: 0.0838 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0828 - tp: 874.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9190 - binary accuracy: 0.9780 - val_loss: 0.0889 - val_tp: 237.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8172 - val_binary accuracy: 0.9728\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0817 - tp: 885.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 164.0000 - recall: 0.8437 - precision: 0.9077 - binary accuracy: 0.9778 - val_loss: 0.0919 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0784 - tp: 874.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9210 - binary accuracy: 0.9782 - val_loss: 0.1049 - val_tp: 239.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7785 - val_binary accuracy: 0.9682\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0807 - tp: 879.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9156 - binary accuracy: 0.9781 - val_loss: 0.1214 - val_tp: 240.0000 - val_tn: 2502.0000 - val_fp: 100.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7059 - val_binary accuracy: 0.9574\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0815 - tp: 878.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9061 - binary accuracy: 0.9771 - val_loss: 0.1217 - val_tp: 240.0000 - val_tn: 2514.0000 - val_fp: 88.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7317 - val_binary accuracy: 0.9616\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0819 - tp: 883.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9084 - binary accuracy: 0.9777 - val_loss: 0.1203 - val_tp: 242.0000 - val_tn: 2508.0000 - val_fp: 94.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.7202 - val_binary accuracy: 0.9602\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0808 - tp: 877.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9154 - binary accuracy: 0.9779 - val_loss: 0.0995 - val_tp: 237.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8034 - val_binary accuracy: 0.9710\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0827 - tp: 875.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9153 - binary accuracy: 0.9777 - val_loss: 0.1004 - val_tp: 237.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7980 - val_binary accuracy: 0.9703\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0797 - tp: 880.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9176 - binary accuracy: 0.9783 - val_loss: 0.0922 - val_tp: 237.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8089 - val_binary accuracy: 0.9717\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0809 - tp: 883.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9131 - binary accuracy: 0.9782 - val_loss: 0.0990 - val_tp: 237.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7953 - val_binary accuracy: 0.9700\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0819 - tp: 880.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9176 - binary accuracy: 0.9783 - val_loss: 0.0899 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0823 - tp: 852.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9161 - binary accuracy: 0.9760 - val_loss: 0.0898 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0830 - tp: 869.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9196 - binary accuracy: 0.9776 - val_loss: 0.0890 - val_tp: 235.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8188 - val_binary accuracy: 0.9724\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0827 - tp: 875.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9086 - binary accuracy: 0.9771 - val_loss: 0.0851 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0813 - tp: 881.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9139 - binary accuracy: 0.9781 - val_loss: 0.0990 - val_tp: 239.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7914 - val_binary accuracy: 0.9700\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0817 - tp: 871.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9120 - binary accuracy: 0.9771 - val_loss: 0.1204 - val_tp: 243.0000 - val_tn: 2500.0000 - val_fp: 102.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.7043 - val_binary accuracy: 0.9578\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0819 - tp: 875.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9124 - binary accuracy: 0.9775 - val_loss: 0.0897 - val_tp: 235.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8217 - val_binary accuracy: 0.9728\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0812 - tp: 877.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9193 - binary accuracy: 0.9783 - val_loss: 0.1184 - val_tp: 243.0000 - val_tn: 2506.0000 - val_fp: 96.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.7168 - val_binary accuracy: 0.9598\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0783 - tp: 884.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 165.0000 - recall: 0.8427 - precision: 0.9247 - binary accuracy: 0.9793 - val_loss: 0.0865 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0787 - tp: 877.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9154 - binary accuracy: 0.9779 - val_loss: 0.0928 - val_tp: 237.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8144 - val_binary accuracy: 0.9724\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0815 - tp: 873.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9209 - binary accuracy: 0.9781 - val_loss: 0.0941 - val_tp: 237.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8089 - val_binary accuracy: 0.9717\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0799 - tp: 875.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9143 - binary accuracy: 0.9776 - val_loss: 0.0912 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0788 - tp: 875.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9153 - binary accuracy: 0.9777 - val_loss: 0.0886 - val_tp: 237.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8201 - val_binary accuracy: 0.9731\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0796 - tp: 874.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9229 - binary accuracy: 0.9783 - val_loss: 0.0890 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0802 - tp: 862.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9151 - binary accuracy: 0.9767 - val_loss: 0.1010 - val_tp: 238.0000 - val_tn: 2535.0000 - val_fp: 67.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7803 - val_binary accuracy: 0.9682\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0816 - tp: 881.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9139 - binary accuracy: 0.9781 - val_loss: 0.0899 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0799 - tp: 881.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9196 - binary accuracy: 0.9786 - val_loss: 0.1101 - val_tp: 240.0000 - val_tn: 2510.0000 - val_fp: 92.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7229 - val_binary accuracy: 0.9602\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0824 - tp: 882.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 167.0000 - recall: 0.8408 - precision: 0.9178 - binary accuracy: 0.9785 - val_loss: 0.0849 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0829 - tp: 871.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9188 - binary accuracy: 0.9777 - val_loss: 0.0905 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0808 - tp: 887.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 162.0000 - recall: 0.8456 - precision: 0.9182 - binary accuracy: 0.9790 - val_loss: 0.0870 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0830 - tp: 883.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9066 - binary accuracy: 0.9776 - val_loss: 0.0812 - val_tp: 234.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8478 - val_binary accuracy: 0.9756\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0855 - tp: 860.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9198 - binary accuracy: 0.9770 - val_loss: 0.0775 - val_tp: 228.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 34.0000 - val_recall: 0.8702 - val_precision: 0.8803 - val_binary accuracy: 0.9773\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0839 - tp: 864.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9191 - binary accuracy: 0.9772 - val_loss: 0.0888 - val_tp: 234.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8269 - val_binary accuracy: 0.9731\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0790 - tp: 886.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 163.0000 - recall: 0.8446 - precision: 0.9210 - binary accuracy: 0.9791 - val_loss: 0.1323 - val_tp: 243.0000 - val_tn: 2471.0000 - val_fp: 131.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.6497 - val_binary accuracy: 0.9476\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0789 - tp: 884.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 165.0000 - recall: 0.8427 - precision: 0.9132 - binary accuracy: 0.9783 - val_loss: 0.1011 - val_tp: 239.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7888 - val_binary accuracy: 0.9696\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0798 - tp: 875.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9086 - binary accuracy: 0.9771 - val_loss: 0.1054 - val_tp: 239.0000 - val_tn: 2532.0000 - val_fp: 70.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7735 - val_binary accuracy: 0.9675\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0815 - tp: 867.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9175 - binary accuracy: 0.9773 - val_loss: 0.0927 - val_tp: 237.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8144 - val_binary accuracy: 0.9724\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0820 - tp: 872.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9074 - binary accuracy: 0.9768 - val_loss: 0.0901 - val_tp: 237.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8144 - val_binary accuracy: 0.9724\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0795 - tp: 875.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9230 - binary accuracy: 0.9784 - val_loss: 0.0769 - val_tp: 227.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 35.0000 - val_recall: 0.8664 - val_precision: 0.8937 - val_binary accuracy: 0.9784\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0799 - tp: 869.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9264 - binary accuracy: 0.9783 - val_loss: 0.0826 - val_tp: 235.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8393 - val_binary accuracy: 0.9749\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0800 - tp: 874.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9066 - binary accuracy: 0.9769 - val_loss: 0.0776 - val_tp: 233.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8826 - val_binary accuracy: 0.9791\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0834 - tp: 861.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9130 - binary accuracy: 0.9764 - val_loss: 0.0805 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0819 - tp: 867.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9155 - binary accuracy: 0.9771 - val_loss: 0.0882 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0832 - tp: 886.0000 - tn: 10301.0000 - fp: 104.0000 - fn: 163.0000 - recall: 0.8446 - precision: 0.8949 - binary accuracy: 0.9767 - val_loss: 0.0821 - val_tp: 234.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8448 - val_binary accuracy: 0.9752\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0790 - tp: 863.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9270 - binary accuracy: 0.9778 - val_loss: 0.0758 - val_tp: 225.0000 - val_tn: 2578.0000 - val_fp: 24.0000 - val_fn: 37.0000 - val_recall: 0.8588 - val_precision: 0.9036 - val_binary accuracy: 0.9787\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0788 - tp: 863.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9220 - binary accuracy: 0.9774 - val_loss: 0.0788 - val_tp: 230.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 32.0000 - val_recall: 0.8779 - val_precision: 0.8745 - val_binary accuracy: 0.9773\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.0814 - tp: 875.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9067 - binary accuracy: 0.9770 - val_loss: 0.0956 - val_tp: 236.0000 - val_tn: 2540.0000 - val_fp: 62.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7919 - val_binary accuracy: 0.9693\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0817 - tp: 877.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9261 - binary accuracy: 0.9789 - val_loss: 0.0848 - val_tp: 235.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8333 - val_binary accuracy: 0.9742\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0811 - tp: 879.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9099 - binary accuracy: 0.9776 - val_loss: 0.1061 - val_tp: 238.0000 - val_tn: 2529.0000 - val_fp: 73.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7653 - val_binary accuracy: 0.9661\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0805 - tp: 874.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9229 - binary accuracy: 0.9783 - val_loss: 0.1101 - val_tp: 238.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7604 - val_binary accuracy: 0.9654\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0785 - tp: 869.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9167 - binary accuracy: 0.9774 - val_loss: 0.1230 - val_tp: 242.0000 - val_tn: 2511.0000 - val_fp: 91.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.7267 - val_binary accuracy: 0.9612\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0787 - tp: 876.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9260 - binary accuracy: 0.9788 - val_loss: 0.1172 - val_tp: 238.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7628 - val_binary accuracy: 0.9658\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0805 - tp: 879.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9272 - binary accuracy: 0.9791 - val_loss: 0.1300 - val_tp: 242.0000 - val_tn: 2503.0000 - val_fp: 99.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.7097 - val_binary accuracy: 0.9584\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0819 - tp: 864.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9114 - binary accuracy: 0.9765 - val_loss: 0.1134 - val_tp: 239.0000 - val_tn: 2523.0000 - val_fp: 79.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7516 - val_binary accuracy: 0.9644\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0794 - tp: 890.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 159.0000 - recall: 0.8484 - precision: 0.9223 - binary accuracy: 0.9796 - val_loss: 0.1956 - val_tp: 246.0000 - val_tn: 2370.0000 - val_fp: 232.0000 - val_fn: 16.0000 - val_recall: 0.9389 - val_precision: 0.5146 - val_binary accuracy: 0.9134\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0787 - tp: 879.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9224 - binary accuracy: 0.9787 - val_loss: 0.1303 - val_tp: 241.0000 - val_tn: 2503.0000 - val_fp: 99.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7088 - val_binary accuracy: 0.9581\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0818 - tp: 865.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9212 - binary accuracy: 0.9775 - val_loss: 0.1030 - val_tp: 237.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7874 - val_binary accuracy: 0.9689\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0803 - tp: 879.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9081 - binary accuracy: 0.9774 - val_loss: 0.1004 - val_tp: 237.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7900 - val_binary accuracy: 0.9693\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0829 - tp: 861.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9160 - binary accuracy: 0.9767 - val_loss: 0.0776 - val_tp: 232.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8958 - val_binary accuracy: 0.9801\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0822 - tp: 872.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9160 - binary accuracy: 0.9776 - val_loss: 0.0968 - val_tp: 237.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7980 - val_binary accuracy: 0.9703\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0806 - tp: 876.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9135 - binary accuracy: 0.9776 - val_loss: 0.0888 - val_tp: 237.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8287 - val_binary accuracy: 0.9742\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0795 - tp: 883.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9141 - binary accuracy: 0.9783 - val_loss: 0.0870 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0799 - tp: 873.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9277 - binary accuracy: 0.9787 - val_loss: 0.0832 - val_tp: 234.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8540 - val_binary accuracy: 0.9763\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0788 - tp: 874.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9171 - binary accuracy: 0.9778 - val_loss: 0.0826 - val_tp: 234.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8509 - val_binary accuracy: 0.9759\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0808 - tp: 861.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9228 - binary accuracy: 0.9773 - val_loss: 0.0830 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0817 - tp: 864.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9066 - binary accuracy: 0.9761 - val_loss: 0.0889 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0814 - tp: 860.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9159 - binary accuracy: 0.9766 - val_loss: 0.0907 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0800 - tp: 867.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9146 - binary accuracy: 0.9770 - val_loss: 0.1011 - val_tp: 238.0000 - val_tn: 2537.0000 - val_fp: 65.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7855 - val_binary accuracy: 0.9689\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0808 - tp: 878.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9155 - binary accuracy: 0.9780 - val_loss: 0.0829 - val_tp: 234.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8571 - val_binary accuracy: 0.9766\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0823 - tp: 868.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9070 - binary accuracy: 0.9764 - val_loss: 0.0890 - val_tp: 237.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8229 - val_binary accuracy: 0.9735\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0795 - tp: 875.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9143 - binary accuracy: 0.9776 - val_loss: 0.0775 - val_tp: 233.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8859 - val_binary accuracy: 0.9794\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0793 - tp: 870.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9187 - binary accuracy: 0.9776 - val_loss: 0.0751 - val_tp: 229.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8980 - val_binary accuracy: 0.9794\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0791 - tp: 871.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9188 - binary accuracy: 0.9777 - val_loss: 0.0778 - val_tp: 232.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8788 - val_binary accuracy: 0.9784\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0825 - tp: 856.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9145 - binary accuracy: 0.9762 - val_loss: 0.0781 - val_tp: 232.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8923 - val_binary accuracy: 0.9797\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0813 - tp: 871.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9207 - binary accuracy: 0.9779 - val_loss: 0.0827 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0822 - tp: 852.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9103 - binary accuracy: 0.9755 - val_loss: 0.0803 - val_tp: 231.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8953 - val_binary accuracy: 0.9797\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0802 - tp: 873.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9151 - binary accuracy: 0.9776 - val_loss: 0.1069 - val_tp: 238.0000 - val_tn: 2529.0000 - val_fp: 73.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7653 - val_binary accuracy: 0.9661\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0802 - tp: 878.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9203 - binary accuracy: 0.9784 - val_loss: 0.0838 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0820 - tp: 865.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9096 - binary accuracy: 0.9764 - val_loss: 0.0843 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0789 - tp: 884.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 165.0000 - recall: 0.8427 - precision: 0.9151 - binary accuracy: 0.9784 - val_loss: 0.0809 - val_tp: 233.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8566 - val_binary accuracy: 0.9763\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0796 - tp: 876.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9221 - binary accuracy: 0.9784 - val_loss: 0.0910 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0787 - tp: 865.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9124 - binary accuracy: 0.9767 - val_loss: 0.0881 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0815 - tp: 870.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9148 - binary accuracy: 0.9773 - val_loss: 0.1012 - val_tp: 239.0000 - val_tn: 2535.0000 - val_fp: 67.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7810 - val_binary accuracy: 0.9686\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0818 - tp: 883.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9131 - binary accuracy: 0.9782 - val_loss: 0.0864 - val_tp: 234.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8417 - val_binary accuracy: 0.9749\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0796 - tp: 870.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9197 - binary accuracy: 0.9777 - val_loss: 0.0869 - val_tp: 233.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8412 - val_binary accuracy: 0.9745\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0799 - tp: 878.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9203 - binary accuracy: 0.9784 - val_loss: 0.1129 - val_tp: 240.0000 - val_tn: 2516.0000 - val_fp: 86.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7362 - val_binary accuracy: 0.9623\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0802 - tp: 879.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9109 - binary accuracy: 0.9776 - val_loss: 0.0959 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0791 - tp: 872.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9286 - binary accuracy: 0.9787 - val_loss: 0.1122 - val_tp: 238.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7628 - val_binary accuracy: 0.9658\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0800 - tp: 875.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9162 - binary accuracy: 0.9778 - val_loss: 0.1075 - val_tp: 237.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7770 - val_binary accuracy: 0.9675\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0833 - tp: 870.0000 - tn: 10307.0000 - fp: 98.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.8988 - binary accuracy: 0.9758 - val_loss: 0.1088 - val_tp: 238.0000 - val_tn: 2531.0000 - val_fp: 71.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7702 - val_binary accuracy: 0.9668\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0770 - tp: 872.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9286 - binary accuracy: 0.9787 - val_loss: 0.0814 - val_tp: 231.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8783 - val_binary accuracy: 0.9780\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0822 - tp: 865.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9241 - binary accuracy: 0.9777 - val_loss: 0.1233 - val_tp: 241.0000 - val_tn: 2499.0000 - val_fp: 103.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7006 - val_binary accuracy: 0.9567\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0824 - tp: 874.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9095 - binary accuracy: 0.9771 - val_loss: 0.1147 - val_tp: 237.0000 - val_tn: 2530.0000 - val_fp: 72.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7670 - val_binary accuracy: 0.9661\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0802 - tp: 848.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9288 - binary accuracy: 0.9768 - val_loss: 0.0744 - val_tp: 219.0000 - val_tn: 2580.0000 - val_fp: 22.0000 - val_fn: 43.0000 - val_recall: 0.8359 - val_precision: 0.9087 - val_binary accuracy: 0.9773\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0802 - tp: 867.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9253 - binary accuracy: 0.9780 - val_loss: 0.0762 - val_tp: 231.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8851 - val_binary accuracy: 0.9787\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0798 - tp: 879.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9099 - binary accuracy: 0.9776 - val_loss: 0.0916 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0818 - tp: 868.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9099 - binary accuracy: 0.9767 - val_loss: 0.0847 - val_tp: 235.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8453 - val_binary accuracy: 0.9756\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0804 - tp: 867.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9243 - binary accuracy: 0.9779 - val_loss: 0.0847 - val_tp: 234.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8540 - val_binary accuracy: 0.9763\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0811 - tp: 862.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9131 - binary accuracy: 0.9765 - val_loss: 0.1037 - val_tp: 239.0000 - val_tn: 2532.0000 - val_fp: 70.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7735 - val_binary accuracy: 0.9675\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0778 - tp: 884.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 165.0000 - recall: 0.8427 - precision: 0.9161 - binary accuracy: 0.9785 - val_loss: 0.0968 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0807 - tp: 870.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9255 - binary accuracy: 0.9783 - val_loss: 0.1083 - val_tp: 236.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7946 - val_binary accuracy: 0.9696\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0828 - tp: 858.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9236 - binary accuracy: 0.9771 - val_loss: 0.1181 - val_tp: 239.0000 - val_tn: 2522.0000 - val_fp: 80.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7492 - val_binary accuracy: 0.9640\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0802 - tp: 871.0000 - tn: 10308.0000 - fp: 97.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.8998 - binary accuracy: 0.9760 - val_loss: 0.1155 - val_tp: 240.0000 - val_tn: 2526.0000 - val_fp: 76.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7595 - val_binary accuracy: 0.9658\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0822 - tp: 870.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9295 - binary accuracy: 0.9786 - val_loss: 0.0914 - val_tp: 233.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8442 - val_binary accuracy: 0.9749\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0792 - tp: 874.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9278 - binary accuracy: 0.9788 - val_loss: 0.1156 - val_tp: 238.0000 - val_tn: 2532.0000 - val_fp: 70.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7727 - val_binary accuracy: 0.9672\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0807 - tp: 866.0000 - tn: 10310.0000 - fp: 95.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9011 - binary accuracy: 0.9757 - val_loss: 0.1255 - val_tp: 241.0000 - val_tn: 2499.0000 - val_fp: 103.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7006 - val_binary accuracy: 0.9567\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0809 - tp: 869.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9196 - binary accuracy: 0.9776 - val_loss: 0.0903 - val_tp: 234.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8211 - val_binary accuracy: 0.9724\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0789 - tp: 875.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9211 - binary accuracy: 0.9783 - val_loss: 0.1102 - val_tp: 237.0000 - val_tn: 2526.0000 - val_fp: 76.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7572 - val_binary accuracy: 0.9647\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0802 - tp: 872.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9257 - binary accuracy: 0.9784 - val_loss: 0.1565 - val_tp: 244.0000 - val_tn: 2465.0000 - val_fp: 137.0000 - val_fn: 18.0000 - val_recall: 0.9313 - val_precision: 0.6404 - val_binary accuracy: 0.9459\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0800 - tp: 876.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9106 - binary accuracy: 0.9774 - val_loss: 0.1334 - val_tp: 241.0000 - val_tn: 2504.0000 - val_fp: 98.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7109 - val_binary accuracy: 0.9584\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0813 - tp: 871.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9188 - binary accuracy: 0.9777 - val_loss: 0.1434 - val_tp: 243.0000 - val_tn: 2487.0000 - val_fp: 115.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.6788 - val_binary accuracy: 0.9532\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0771 - tp: 873.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9075 - binary accuracy: 0.9769 - val_loss: 0.1150 - val_tp: 238.0000 - val_tn: 2531.0000 - val_fp: 71.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7702 - val_binary accuracy: 0.9668\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0774 - tp: 877.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9310 - binary accuracy: 0.9793 - val_loss: 0.1050 - val_tp: 236.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8000 - val_binary accuracy: 0.9703\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0803 - tp: 864.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9172 - binary accuracy: 0.9770 - val_loss: 0.1002 - val_tp: 236.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8055 - val_binary accuracy: 0.9710\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0805 - tp: 870.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9119 - binary accuracy: 0.9770 - val_loss: 0.0885 - val_tp: 234.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8417 - val_binary accuracy: 0.9749\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0805 - tp: 860.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9267 - binary accuracy: 0.9776 - val_loss: 0.0904 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0813 - tp: 859.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9100 - binary accuracy: 0.9760 - val_loss: 0.0899 - val_tp: 236.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8339 - val_binary accuracy: 0.9745\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0836 - tp: 874.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9104 - binary accuracy: 0.9772 - val_loss: 0.0905 - val_tp: 234.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8417 - val_binary accuracy: 0.9749\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0818 - tp: 859.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9207 - binary accuracy: 0.9770 - val_loss: 0.0902 - val_tp: 234.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8269 - val_binary accuracy: 0.9731\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0805 - tp: 871.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9130 - binary accuracy: 0.9772 - val_loss: 0.0910 - val_tp: 235.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8275 - val_binary accuracy: 0.9735\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0777 - tp: 873.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9287 - binary accuracy: 0.9788 - val_loss: 0.0914 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0787 - tp: 860.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9247 - binary accuracy: 0.9774 - val_loss: 0.0926 - val_tp: 236.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8223 - val_binary accuracy: 0.9731\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0795 - tp: 885.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 164.0000 - recall: 0.8437 - precision: 0.9114 - binary accuracy: 0.9782 - val_loss: 0.0965 - val_tp: 237.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8116 - val_binary accuracy: 0.9721\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0816 - tp: 868.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9127 - binary accuracy: 0.9770 - val_loss: 0.0807 - val_tp: 232.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8722 - val_binary accuracy: 0.9777\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0821 - tp: 857.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9225 - binary accuracy: 0.9770 - val_loss: 0.0912 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0780 - tp: 876.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9154 - binary accuracy: 0.9778 - val_loss: 0.0749 - val_tp: 226.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.8968 - val_binary accuracy: 0.9784\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0812 - tp: 860.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9168 - binary accuracy: 0.9767 - val_loss: 0.0836 - val_tp: 235.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8363 - val_binary accuracy: 0.9745\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0792 - tp: 875.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9115 - binary accuracy: 0.9774 - val_loss: 0.0788 - val_tp: 232.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8855 - val_binary accuracy: 0.9791\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0811 - tp: 856.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9254 - binary accuracy: 0.9771 - val_loss: 0.0919 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0793 - tp: 878.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9155 - binary accuracy: 0.9780 - val_loss: 0.0902 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0792 - tp: 866.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9203 - binary accuracy: 0.9775 - val_loss: 0.0925 - val_tp: 236.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8223 - val_binary accuracy: 0.9731\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0793 - tp: 879.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9071 - binary accuracy: 0.9773 - val_loss: 0.1195 - val_tp: 239.0000 - val_tn: 2504.0000 - val_fp: 98.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7092 - val_binary accuracy: 0.9578\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0795 - tp: 867.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9204 - binary accuracy: 0.9776 - val_loss: 0.0770 - val_tp: 227.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 35.0000 - val_recall: 0.8664 - val_precision: 0.8972 - val_binary accuracy: 0.9787\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0813 - tp: 865.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9232 - binary accuracy: 0.9776 - val_loss: 0.0915 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0813 - tp: 870.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9062 - binary accuracy: 0.9765 - val_loss: 0.0823 - val_tp: 234.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8478 - val_binary accuracy: 0.9756\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0818 - tp: 864.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9191 - binary accuracy: 0.9772 - val_loss: 0.0798 - val_tp: 234.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8797 - val_binary accuracy: 0.9791\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0794 - tp: 885.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 164.0000 - recall: 0.8437 - precision: 0.9219 - binary accuracy: 0.9791 - val_loss: 0.0879 - val_tp: 234.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8327 - val_binary accuracy: 0.9738\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0808 - tp: 879.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9118 - binary accuracy: 0.9777 - val_loss: 0.0874 - val_tp: 234.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8357 - val_binary accuracy: 0.9742\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0833 - tp: 854.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9293 - binary accuracy: 0.9773 - val_loss: 0.0790 - val_tp: 226.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 36.0000 - val_recall: 0.8626 - val_precision: 0.8898 - val_binary accuracy: 0.9777\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0806 - tp: 874.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9190 - binary accuracy: 0.9780 - val_loss: 0.0897 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0813 - tp: 870.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9129 - binary accuracy: 0.9771 - val_loss: 0.0993 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0768 - tp: 875.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9182 - binary accuracy: 0.9780 - val_loss: 0.0940 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0801 - tp: 863.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9191 - binary accuracy: 0.9771 - val_loss: 0.0787 - val_tp: 232.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8889 - val_binary accuracy: 0.9794\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.0767 - tp: 876.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9241 - binary accuracy: 0.9786 - val_loss: 0.0863 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0789 - tp: 874.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9133 - binary accuracy: 0.9775 - val_loss: 0.0924 - val_tp: 236.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8223 - val_binary accuracy: 0.9731\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0798 - tp: 866.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9262 - binary accuracy: 0.9780 - val_loss: 0.1013 - val_tp: 236.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7973 - val_binary accuracy: 0.9700\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0802 - tp: 867.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9079 - binary accuracy: 0.9764 - val_loss: 0.0945 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0770 - tp: 868.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9293 - binary accuracy: 0.9784 - val_loss: 0.0961 - val_tp: 237.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8172 - val_binary accuracy: 0.9728\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0759 - tp: 872.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9198 - binary accuracy: 0.9779 - val_loss: 0.0917 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0810 - tp: 865.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9222 - binary accuracy: 0.9776 - val_loss: 0.0824 - val_tp: 232.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8788 - val_binary accuracy: 0.9784\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0806 - tp: 859.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9168 - binary accuracy: 0.9766 - val_loss: 0.0928 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0793 - tp: 865.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9202 - binary accuracy: 0.9774 - val_loss: 0.0757 - val_tp: 229.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8980 - val_binary accuracy: 0.9794\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0792 - tp: 863.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9191 - binary accuracy: 0.9771 - val_loss: 0.0840 - val_tp: 235.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8423 - val_binary accuracy: 0.9752\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0830 - tp: 865.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9048 - binary accuracy: 0.9760 - val_loss: 0.0830 - val_tp: 234.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8571 - val_binary accuracy: 0.9766\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0801 - tp: 867.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9146 - binary accuracy: 0.9770 - val_loss: 0.0828 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0781 - tp: 870.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9158 - binary accuracy: 0.9774 - val_loss: 0.0869 - val_tp: 235.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8363 - val_binary accuracy: 0.9745\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0809 - tp: 861.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9160 - binary accuracy: 0.9767 - val_loss: 0.0801 - val_tp: 233.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8792 - val_binary accuracy: 0.9787\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0792 - tp: 872.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9316 - binary accuracy: 0.9790 - val_loss: 0.0903 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0780 - tp: 874.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9210 - binary accuracy: 0.9782 - val_loss: 0.0828 - val_tp: 234.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8731 - val_binary accuracy: 0.9784\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0820 - tp: 858.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9157 - binary accuracy: 0.9764 - val_loss: 0.1032 - val_tp: 238.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7881 - val_binary accuracy: 0.9693\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0792 - tp: 876.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9116 - binary accuracy: 0.9775 - val_loss: 0.1178 - val_tp: 239.0000 - val_tn: 2523.0000 - val_fp: 79.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7516 - val_binary accuracy: 0.9644\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0805 - tp: 861.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9179 - binary accuracy: 0.9769 - val_loss: 0.1312 - val_tp: 243.0000 - val_tn: 2502.0000 - val_fp: 100.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.7085 - val_binary accuracy: 0.9584\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0794 - tp: 878.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9136 - binary accuracy: 0.9778 - val_loss: 0.1293 - val_tp: 240.0000 - val_tn: 2511.0000 - val_fp: 91.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7251 - val_binary accuracy: 0.9605\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0774 - tp: 869.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9225 - binary accuracy: 0.9779 - val_loss: 0.1186 - val_tp: 239.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7636 - val_binary accuracy: 0.9661\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0778 - tp: 876.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9211 - binary accuracy: 0.9783 - val_loss: 0.1144 - val_tp: 238.0000 - val_tn: 2531.0000 - val_fp: 71.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7702 - val_binary accuracy: 0.9668\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0793 - tp: 872.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9189 - binary accuracy: 0.9778 - val_loss: 0.1139 - val_tp: 237.0000 - val_tn: 2525.0000 - val_fp: 77.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7548 - val_binary accuracy: 0.9644\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0777 - tp: 858.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9216 - binary accuracy: 0.9770 - val_loss: 0.1113 - val_tp: 237.0000 - val_tn: 2532.0000 - val_fp: 70.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7720 - val_binary accuracy: 0.9668\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0812 - tp: 862.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9180 - binary accuracy: 0.9770 - val_loss: 0.1721 - val_tp: 244.0000 - val_tn: 2457.0000 - val_fp: 145.0000 - val_fn: 18.0000 - val_recall: 0.9313 - val_precision: 0.6272 - val_binary accuracy: 0.9431\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0813 - tp: 872.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9074 - binary accuracy: 0.9768 - val_loss: 0.1322 - val_tp: 239.0000 - val_tn: 2506.0000 - val_fp: 96.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7134 - val_binary accuracy: 0.9584\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0772 - tp: 883.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9160 - binary accuracy: 0.9784 - val_loss: 0.1416 - val_tp: 239.0000 - val_tn: 2506.0000 - val_fp: 96.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7134 - val_binary accuracy: 0.9584\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0801 - tp: 870.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9187 - binary accuracy: 0.9776 - val_loss: 0.1631 - val_tp: 244.0000 - val_tn: 2502.0000 - val_fp: 100.0000 - val_fn: 18.0000 - val_recall: 0.9313 - val_precision: 0.7093 - val_binary accuracy: 0.9588\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0784 - tp: 867.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9175 - binary accuracy: 0.9773 - val_loss: 0.1482 - val_tp: 243.0000 - val_tn: 2488.0000 - val_fp: 114.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.6807 - val_binary accuracy: 0.9536\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0807 - tp: 874.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9085 - binary accuracy: 0.9770 - val_loss: 0.1251 - val_tp: 240.0000 - val_tn: 2508.0000 - val_fp: 94.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7186 - val_binary accuracy: 0.9595\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0796 - tp: 853.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9172 - binary accuracy: 0.9762 - val_loss: 0.0920 - val_tp: 235.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8275 - val_binary accuracy: 0.9735\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0836 - tp: 850.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9290 - binary accuracy: 0.9770 - val_loss: 0.0819 - val_tp: 232.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8821 - val_binary accuracy: 0.9787\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0797 - tp: 882.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 167.0000 - recall: 0.8408 - precision: 0.9197 - binary accuracy: 0.9787 - val_loss: 0.1045 - val_tp: 236.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7973 - val_binary accuracy: 0.9700\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0804 - tp: 873.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9141 - binary accuracy: 0.9775 - val_loss: 0.0877 - val_tp: 234.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8448 - val_binary accuracy: 0.9752\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0804 - tp: 874.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9161 - binary accuracy: 0.9777 - val_loss: 0.0834 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0813 - tp: 856.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9264 - binary accuracy: 0.9772 - val_loss: 0.0767 - val_tp: 232.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8958 - val_binary accuracy: 0.9801\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0790 - tp: 868.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9274 - binary accuracy: 0.9783 - val_loss: 0.0802 - val_tp: 234.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8797 - val_binary accuracy: 0.9791\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0817 - tp: 872.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9074 - binary accuracy: 0.9768 - val_loss: 0.0865 - val_tp: 234.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8448 - val_binary accuracy: 0.9752\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0801 - tp: 867.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9223 - binary accuracy: 0.9777 - val_loss: 0.0890 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0821 - tp: 866.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9174 - binary accuracy: 0.9772 - val_loss: 0.0808 - val_tp: 233.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8893 - val_binary accuracy: 0.9797\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0787 - tp: 858.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9286 - binary accuracy: 0.9776 - val_loss: 0.1055 - val_tp: 238.0000 - val_tn: 2537.0000 - val_fp: 65.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7855 - val_binary accuracy: 0.9689\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0806 - tp: 870.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9158 - binary accuracy: 0.9774 - val_loss: 0.0984 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0758 - tp: 881.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9130 - binary accuracy: 0.9780 - val_loss: 0.1396 - val_tp: 242.0000 - val_tn: 2486.0000 - val_fp: 116.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.6760 - val_binary accuracy: 0.9525\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0807 - tp: 878.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9146 - binary accuracy: 0.9779 - val_loss: 0.1094 - val_tp: 237.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8061 - val_binary accuracy: 0.9714\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0795 - tp: 860.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9247 - binary accuracy: 0.9774 - val_loss: 0.1491 - val_tp: 243.0000 - val_tn: 2485.0000 - val_fp: 117.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.6750 - val_binary accuracy: 0.9525\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0817 - tp: 867.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9117 - binary accuracy: 0.9768 - val_loss: 0.1131 - val_tp: 236.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7973 - val_binary accuracy: 0.9700\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0820 - tp: 847.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9207 - binary accuracy: 0.9760 - val_loss: 0.1441 - val_tp: 242.0000 - val_tn: 2500.0000 - val_fp: 102.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.7035 - val_binary accuracy: 0.9574\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.0791 - tp: 868.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9137 - binary accuracy: 0.9770 - val_loss: 0.1086 - val_tp: 237.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8007 - val_binary accuracy: 0.9707\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0795 - tp: 859.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9286 - binary accuracy: 0.9776 - val_loss: 0.0935 - val_tp: 236.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8223 - val_binary accuracy: 0.9731\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0811 - tp: 866.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9174 - binary accuracy: 0.9772 - val_loss: 0.0763 - val_tp: 232.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8923 - val_binary accuracy: 0.9797\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0821 - tp: 866.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9087 - binary accuracy: 0.9764 - val_loss: 0.0789 - val_tp: 233.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8792 - val_binary accuracy: 0.9787\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0770 - tp: 873.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9258 - binary accuracy: 0.9785 - val_loss: 0.1032 - val_tp: 238.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7778 - val_binary accuracy: 0.9679\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0787 - tp: 871.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9246 - binary accuracy: 0.9783 - val_loss: 0.0812 - val_tp: 232.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8821 - val_binary accuracy: 0.9787\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0811 - tp: 867.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9175 - binary accuracy: 0.9773 - val_loss: 0.0909 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0814 - tp: 861.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9179 - binary accuracy: 0.9769 - val_loss: 0.0856 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0785 - tp: 874.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9239 - binary accuracy: 0.9784 - val_loss: 0.0878 - val_tp: 234.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8387 - val_binary accuracy: 0.9745\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0802 - tp: 859.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9337 - binary accuracy: 0.9781 - val_loss: 0.0751 - val_tp: 222.0000 - val_tn: 2578.0000 - val_fp: 24.0000 - val_fn: 40.0000 - val_recall: 0.8473 - val_precision: 0.9024 - val_binary accuracy: 0.9777\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0807 - tp: 872.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9218 - binary accuracy: 0.9781 - val_loss: 0.0834 - val_tp: 233.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8694 - val_binary accuracy: 0.9777\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0816 - tp: 867.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9088 - binary accuracy: 0.9765 - val_loss: 0.1023 - val_tp: 236.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8055 - val_binary accuracy: 0.9710\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0796 - tp: 855.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9273 - binary accuracy: 0.9772 - val_loss: 0.0973 - val_tp: 234.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8509 - val_binary accuracy: 0.9759\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0812 - tp: 855.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9253 - binary accuracy: 0.9770 - val_loss: 0.1043 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0792 - tp: 872.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9160 - binary accuracy: 0.9776 - val_loss: 0.1585 - val_tp: 244.0000 - val_tn: 2458.0000 - val_fp: 144.0000 - val_fn: 18.0000 - val_recall: 0.9313 - val_precision: 0.6289 - val_binary accuracy: 0.9434\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0818 - tp: 860.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9081 - binary accuracy: 0.9759 - val_loss: 0.0972 - val_tp: 235.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8275 - val_binary accuracy: 0.9735\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0808 - tp: 863.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9142 - binary accuracy: 0.9767 - val_loss: 0.1090 - val_tp: 236.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8027 - val_binary accuracy: 0.9707\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0774 - tp: 866.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9262 - binary accuracy: 0.9780 - val_loss: 0.1501 - val_tp: 242.0000 - val_tn: 2487.0000 - val_fp: 115.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.6779 - val_binary accuracy: 0.9529\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0784 - tp: 873.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9141 - binary accuracy: 0.9775 - val_loss: 0.1031 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0797 - tp: 865.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9241 - binary accuracy: 0.9777 - val_loss: 0.1012 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0790 - tp: 868.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9303 - binary accuracy: 0.9785 - val_loss: 0.0884 - val_tp: 233.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8442 - val_binary accuracy: 0.9749\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0769 - tp: 871.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9140 - binary accuracy: 0.9773 - val_loss: 0.1349 - val_tp: 242.0000 - val_tn: 2513.0000 - val_fp: 89.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.7311 - val_binary accuracy: 0.9619\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0802 - tp: 882.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 167.0000 - recall: 0.8408 - precision: 0.9112 - binary accuracy: 0.9779 - val_loss: 0.1460 - val_tp: 243.0000 - val_tn: 2501.0000 - val_fp: 101.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.7064 - val_binary accuracy: 0.9581\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0797 - tp: 871.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9217 - binary accuracy: 0.9780 - val_loss: 0.1048 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0785 - tp: 869.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9186 - binary accuracy: 0.9776 - val_loss: 0.1131 - val_tp: 239.0000 - val_tn: 2529.0000 - val_fp: 73.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7660 - val_binary accuracy: 0.9665\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0769 - tp: 866.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9232 - binary accuracy: 0.9777 - val_loss: 0.0978 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0783 - tp: 885.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 164.0000 - recall: 0.8437 - precision: 0.9296 - binary accuracy: 0.9798 - val_loss: 0.0920 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0797 - tp: 863.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9300 - binary accuracy: 0.9781 - val_loss: 0.1151 - val_tp: 239.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7636 - val_binary accuracy: 0.9661\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0765 - tp: 876.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9106 - binary accuracy: 0.9774 - val_loss: 0.0957 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0775 - tp: 866.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9272 - binary accuracy: 0.9781 - val_loss: 0.0926 - val_tp: 235.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8217 - val_binary accuracy: 0.9728\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0770 - tp: 863.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9113 - binary accuracy: 0.9764 - val_loss: 0.0877 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0796 - tp: 872.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9228 - binary accuracy: 0.9782 - val_loss: 0.1029 - val_tp: 237.0000 - val_tn: 2539.0000 - val_fp: 63.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7900 - val_binary accuracy: 0.9693\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0786 - tp: 869.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9167 - binary accuracy: 0.9774 - val_loss: 0.0919 - val_tp: 234.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8269 - val_binary accuracy: 0.9731\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0798 - tp: 867.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9146 - binary accuracy: 0.9770 - val_loss: 0.1302 - val_tp: 242.0000 - val_tn: 2486.0000 - val_fp: 116.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.6760 - val_binary accuracy: 0.9525\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0789 - tp: 881.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9073 - binary accuracy: 0.9775 - val_loss: 0.0821 - val_tp: 231.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8851 - val_binary accuracy: 0.9787\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0815 - tp: 853.0000 - tn: 10345.0000 - fp: 60.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9343 - binary accuracy: 0.9776 - val_loss: 0.0800 - val_tp: 233.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8826 - val_binary accuracy: 0.9791\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0788 - tp: 860.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9081 - binary accuracy: 0.9759 - val_loss: 0.0906 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0788 - tp: 872.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9189 - binary accuracy: 0.9778 - val_loss: 0.0862 - val_tp: 234.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8540 - val_binary accuracy: 0.9763\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0820 - tp: 859.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9276 - binary accuracy: 0.9776 - val_loss: 0.0848 - val_tp: 233.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8473 - val_binary accuracy: 0.9752\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0803 - tp: 870.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9110 - binary accuracy: 0.9770 - val_loss: 0.0956 - val_tp: 236.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8055 - val_binary accuracy: 0.9710\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0773 - tp: 883.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9208 - binary accuracy: 0.9789 - val_loss: 0.0788 - val_tp: 232.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8889 - val_binary accuracy: 0.9794\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0822 - tp: 859.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9227 - binary accuracy: 0.9771 - val_loss: 0.0853 - val_tp: 235.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8393 - val_binary accuracy: 0.9749\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0802 - tp: 872.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9074 - binary accuracy: 0.9768 - val_loss: 0.0803 - val_tp: 233.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8792 - val_binary accuracy: 0.9787\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0802 - tp: 870.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9236 - binary accuracy: 0.9781 - val_loss: 0.0793 - val_tp: 232.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8889 - val_binary accuracy: 0.9794\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0781 - tp: 881.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9168 - binary accuracy: 0.9783 - val_loss: 0.0890 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0784 - tp: 866.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9174 - binary accuracy: 0.9772 - val_loss: 0.0773 - val_tp: 232.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8958 - val_binary accuracy: 0.9801\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0781 - tp: 868.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9303 - binary accuracy: 0.9785 - val_loss: 0.0799 - val_tp: 233.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8859 - val_binary accuracy: 0.9794\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0809 - tp: 867.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9165 - binary accuracy: 0.9772 - val_loss: 0.0941 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0792 - tp: 869.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9071 - binary accuracy: 0.9765 - val_loss: 0.1193 - val_tp: 240.0000 - val_tn: 2509.0000 - val_fp: 93.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7207 - val_binary accuracy: 0.9598\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0811 - tp: 858.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9108 - binary accuracy: 0.9760 - val_loss: 0.0807 - val_tp: 232.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8855 - val_binary accuracy: 0.9791\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0776 - tp: 877.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9183 - binary accuracy: 0.9782 - val_loss: 0.0936 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0799 - tp: 873.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9161 - binary accuracy: 0.9776 - val_loss: 0.0885 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0785 - tp: 871.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9159 - binary accuracy: 0.9775 - val_loss: 0.0877 - val_tp: 235.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8423 - val_binary accuracy: 0.9752\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0800 - tp: 865.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9115 - binary accuracy: 0.9766 - val_loss: 0.0826 - val_tp: 232.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8755 - val_binary accuracy: 0.9780\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0786 - tp: 859.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9297 - binary accuracy: 0.9777 - val_loss: 0.0800 - val_tp: 230.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 32.0000 - val_recall: 0.8779 - val_precision: 0.8846 - val_binary accuracy: 0.9784\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0790 - tp: 864.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9211 - binary accuracy: 0.9774 - val_loss: 0.0926 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0804 - tp: 865.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9134 - binary accuracy: 0.9768 - val_loss: 0.0911 - val_tp: 234.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8448 - val_binary accuracy: 0.9752\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0791 - tp: 866.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9193 - binary accuracy: 0.9774 - val_loss: 0.1403 - val_tp: 243.0000 - val_tn: 2484.0000 - val_fp: 118.0000 - val_fn: 19.0000 - val_recall: 0.9275 - val_precision: 0.6731 - val_binary accuracy: 0.9522\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0795 - tp: 875.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9162 - binary accuracy: 0.9778 - val_loss: 0.0909 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0779 - tp: 864.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9300 - binary accuracy: 0.9782 - val_loss: 0.0921 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0792 - tp: 874.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9219 - binary accuracy: 0.9783 - val_loss: 0.0905 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0809 - tp: 868.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9156 - binary accuracy: 0.9772 - val_loss: 0.1006 - val_tp: 236.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8055 - val_binary accuracy: 0.9710\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0780 - tp: 868.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9224 - binary accuracy: 0.9778 - val_loss: 0.1257 - val_tp: 241.0000 - val_tn: 2514.0000 - val_fp: 88.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7325 - val_binary accuracy: 0.9619\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0806 - tp: 866.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9106 - binary accuracy: 0.9766 - val_loss: 0.1175 - val_tp: 238.0000 - val_tn: 2535.0000 - val_fp: 67.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7803 - val_binary accuracy: 0.9682\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0806 - tp: 860.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9227 - binary accuracy: 0.9772 - val_loss: 0.0971 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0786 - tp: 864.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9143 - binary accuracy: 0.9768 - val_loss: 0.1292 - val_tp: 242.0000 - val_tn: 2493.0000 - val_fp: 109.0000 - val_fn: 20.0000 - val_recall: 0.9237 - val_precision: 0.6895 - val_binary accuracy: 0.9550\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0774 - tp: 872.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9169 - binary accuracy: 0.9776 - val_loss: 0.1038 - val_tp: 236.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8027 - val_binary accuracy: 0.9707\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0796 - tp: 880.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9273 - binary accuracy: 0.9792 - val_loss: 0.0999 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0792 - tp: 859.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9307 - binary accuracy: 0.9778 - val_loss: 0.0845 - val_tp: 234.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8509 - val_binary accuracy: 0.9759\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0775 - tp: 870.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9197 - binary accuracy: 0.9777 - val_loss: 0.1096 - val_tp: 238.0000 - val_tn: 2522.0000 - val_fp: 80.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7484 - val_binary accuracy: 0.9637\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0785 - tp: 859.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9148 - binary accuracy: 0.9764 - val_loss: 0.0813 - val_tp: 229.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 33.0000 - val_recall: 0.8740 - val_precision: 0.8911 - val_binary accuracy: 0.9787\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0774 - tp: 845.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 204.0000 - recall: 0.8055 - precision: 0.9327 - binary accuracy: 0.9769 - val_loss: 0.0904 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0795 - tp: 871.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9168 - binary accuracy: 0.9776 - val_loss: 0.1058 - val_tp: 236.0000 - val_tn: 2531.0000 - val_fp: 71.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7687 - val_binary accuracy: 0.9661\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0790 - tp: 870.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9236 - binary accuracy: 0.9781 - val_loss: 0.0871 - val_tp: 236.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8339 - val_binary accuracy: 0.9745\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0792 - tp: 875.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9077 - binary accuracy: 0.9770 - val_loss: 0.0815 - val_tp: 233.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8566 - val_binary accuracy: 0.9763\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0780 - tp: 859.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9187 - binary accuracy: 0.9768 - val_loss: 0.0860 - val_tp: 235.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8423 - val_binary accuracy: 0.9752\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0783 - tp: 874.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9171 - binary accuracy: 0.9778 - val_loss: 0.0853 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0792 - tp: 865.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9153 - binary accuracy: 0.9770 - val_loss: 0.1130 - val_tp: 238.0000 - val_tn: 2533.0000 - val_fp: 69.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7752 - val_binary accuracy: 0.9675\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0777 - tp: 864.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9162 - binary accuracy: 0.9770 - val_loss: 0.1056 - val_tp: 236.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8055 - val_binary accuracy: 0.9710\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0759 - tp: 856.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9244 - binary accuracy: 0.9770 - val_loss: 0.1000 - val_tp: 236.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8223 - val_binary accuracy: 0.9731\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0791 - tp: 861.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9169 - binary accuracy: 0.9768 - val_loss: 0.1188 - val_tp: 239.0000 - val_tn: 2526.0000 - val_fp: 76.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7587 - val_binary accuracy: 0.9654\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0768 - tp: 879.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9253 - binary accuracy: 0.9790 - val_loss: 0.1117 - val_tp: 237.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8089 - val_binary accuracy: 0.9717\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0783 - tp: 868.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9166 - binary accuracy: 0.9773 - val_loss: 0.1163 - val_tp: 238.0000 - val_tn: 2525.0000 - val_fp: 77.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7556 - val_binary accuracy: 0.9647\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0765 - tp: 875.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9249 - binary accuracy: 0.9786 - val_loss: 0.0798 - val_tp: 232.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8923 - val_binary accuracy: 0.9797\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0806 - tp: 868.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9214 - binary accuracy: 0.9777 - val_loss: 0.0908 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0794 - tp: 861.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9111 - binary accuracy: 0.9763 - val_loss: 0.0869 - val_tp: 235.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8453 - val_binary accuracy: 0.9756\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0788 - tp: 858.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9147 - binary accuracy: 0.9763 - val_loss: 0.0946 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0790 - tp: 863.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9240 - binary accuracy: 0.9776 - val_loss: 0.0912 - val_tp: 236.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8489 - val_binary accuracy: 0.9763\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0811 - tp: 879.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9185 - binary accuracy: 0.9783 - val_loss: 0.1095 - val_tp: 237.0000 - val_tn: 2528.0000 - val_fp: 74.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7621 - val_binary accuracy: 0.9654\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0782 - tp: 861.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9209 - binary accuracy: 0.9771 - val_loss: 0.0931 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0775 - tp: 868.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9205 - binary accuracy: 0.9776 - val_loss: 0.0966 - val_tp: 237.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8089 - val_binary accuracy: 0.9717\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0811 - tp: 863.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9123 - binary accuracy: 0.9765 - val_loss: 0.0855 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0769 - tp: 865.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9301 - binary accuracy: 0.9783 - val_loss: 0.0801 - val_tp: 233.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8893 - val_binary accuracy: 0.9797\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0811 - tp: 878.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9203 - binary accuracy: 0.9784 - val_loss: 0.0831 - val_tp: 234.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8864 - val_binary accuracy: 0.9797\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0791 - tp: 861.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9288 - binary accuracy: 0.9778 - val_loss: 0.0825 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0809 - tp: 859.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9168 - binary accuracy: 0.9766 - val_loss: 0.0822 - val_tp: 233.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8996 - val_binary accuracy: 0.9808\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0776 - tp: 866.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9242 - binary accuracy: 0.9778 - val_loss: 0.1180 - val_tp: 239.0000 - val_tn: 2514.0000 - val_fp: 88.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7309 - val_binary accuracy: 0.9612\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0751 - tp: 871.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9246 - binary accuracy: 0.9783 - val_loss: 0.0772 - val_tp: 231.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8988 - val_binary accuracy: 0.9801\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0756 - tp: 877.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9183 - binary accuracy: 0.9782 - val_loss: 0.0967 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0794 - tp: 854.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9134 - binary accuracy: 0.9759 - val_loss: 0.0795 - val_tp: 232.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8788 - val_binary accuracy: 0.9784\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0790 - tp: 855.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9223 - binary accuracy: 0.9768 - val_loss: 0.0825 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0831 - tp: 863.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9220 - binary accuracy: 0.9774 - val_loss: 0.0760 - val_tp: 228.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 34.0000 - val_recall: 0.8702 - val_precision: 0.8976 - val_binary accuracy: 0.9791\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0782 - tp: 851.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9240 - binary accuracy: 0.9766 - val_loss: 0.0801 - val_tp: 233.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8859 - val_binary accuracy: 0.9794\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0779 - tp: 862.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9299 - binary accuracy: 0.9780 - val_loss: 0.0889 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0763 - tp: 868.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9156 - binary accuracy: 0.9772 - val_loss: 0.0868 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0809 - tp: 846.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 203.0000 - recall: 0.8065 - precision: 0.9156 - binary accuracy: 0.9755 - val_loss: 0.0813 - val_tp: 234.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8897 - val_binary accuracy: 0.9801\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0769 - tp: 865.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9183 - binary accuracy: 0.9772 - val_loss: 0.0886 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0776 - tp: 862.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9190 - binary accuracy: 0.9770 - val_loss: 0.0825 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0789 - tp: 854.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9203 - binary accuracy: 0.9765 - val_loss: 0.0863 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0761 - tp: 871.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9286 - binary accuracy: 0.9786 - val_loss: 0.0827 - val_tp: 234.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8764 - val_binary accuracy: 0.9787\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0773 - tp: 877.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9164 - binary accuracy: 0.9780 - val_loss: 0.1127 - val_tp: 239.0000 - val_tn: 2526.0000 - val_fp: 76.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7587 - val_binary accuracy: 0.9654\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0779 - tp: 874.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9229 - binary accuracy: 0.9783 - val_loss: 0.0873 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0758 - tp: 871.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9256 - binary accuracy: 0.9783 - val_loss: 0.0952 - val_tp: 236.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8339 - val_binary accuracy: 0.9745\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0799 - tp: 858.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9266 - binary accuracy: 0.9774 - val_loss: 0.0838 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0787 - tp: 858.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9206 - binary accuracy: 0.9769 - val_loss: 0.1043 - val_tp: 239.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.8020 - val_binary accuracy: 0.9714\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0777 - tp: 870.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9168 - binary accuracy: 0.9775 - val_loss: 0.0930 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0780 - tp: 862.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9209 - binary accuracy: 0.9772 - val_loss: 0.0900 - val_tp: 236.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8489 - val_binary accuracy: 0.9763\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0797 - tp: 871.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9227 - binary accuracy: 0.9781 - val_loss: 0.0884 - val_tp: 236.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8613 - val_binary accuracy: 0.9777\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0780 - tp: 863.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9310 - binary accuracy: 0.9782 - val_loss: 0.1141 - val_tp: 238.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7604 - val_binary accuracy: 0.9654\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0760 - tp: 878.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9242 - binary accuracy: 0.9788 - val_loss: 0.0964 - val_tp: 237.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8287 - val_binary accuracy: 0.9742\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0788 - tp: 869.0000 - tn: 10316.0000 - fp: 89.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9071 - binary accuracy: 0.9765 - val_loss: 0.0940 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0797 - tp: 869.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9167 - binary accuracy: 0.9774 - val_loss: 0.0776 - val_tp: 232.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8923 - val_binary accuracy: 0.9797\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0782 - tp: 866.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9154 - binary accuracy: 0.9770 - val_loss: 0.0867 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0772 - tp: 875.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 174.0000 - recall: 0.8341 - precision: 0.9153 - binary accuracy: 0.9777 - val_loss: 0.0810 - val_tp: 233.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8792 - val_binary accuracy: 0.9787\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0784 - tp: 868.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9214 - binary accuracy: 0.9777 - val_loss: 0.1016 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0761 - tp: 872.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9208 - binary accuracy: 0.9780 - val_loss: 0.1107 - val_tp: 237.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7874 - val_binary accuracy: 0.9689\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0787 - tp: 859.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9286 - binary accuracy: 0.9776 - val_loss: 0.1002 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0779 - tp: 864.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9231 - binary accuracy: 0.9776 - val_loss: 0.1108 - val_tp: 238.0000 - val_tn: 2540.0000 - val_fp: 62.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7933 - val_binary accuracy: 0.9700\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0776 - tp: 876.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9182 - binary accuracy: 0.9781 - val_loss: 0.1053 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0781 - tp: 863.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9260 - binary accuracy: 0.9777 - val_loss: 0.1015 - val_tp: 236.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8281 - val_binary accuracy: 0.9738\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0789 - tp: 868.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9089 - binary accuracy: 0.9766 - val_loss: 0.1252 - val_tp: 239.0000 - val_tn: 2516.0000 - val_fp: 86.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7354 - val_binary accuracy: 0.9619\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0766 - tp: 879.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9147 - binary accuracy: 0.9780 - val_loss: 0.0877 - val_tp: 234.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8731 - val_binary accuracy: 0.9784\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0757 - tp: 863.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9280 - binary accuracy: 0.9779 - val_loss: 0.0953 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0791 - tp: 867.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9136 - binary accuracy: 0.9770 - val_loss: 0.1189 - val_tp: 241.0000 - val_tn: 2516.0000 - val_fp: 86.0000 - val_fn: 21.0000 - val_recall: 0.9198 - val_precision: 0.7370 - val_binary accuracy: 0.9626\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0784 - tp: 868.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9205 - binary accuracy: 0.9776 - val_loss: 0.0784 - val_tp: 231.0000 - val_tn: 2577.0000 - val_fp: 25.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.9023 - val_binary accuracy: 0.9804\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0804 - tp: 872.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9218 - binary accuracy: 0.9781 - val_loss: 0.1009 - val_tp: 236.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8055 - val_binary accuracy: 0.9710\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0782 - tp: 858.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9266 - binary accuracy: 0.9774 - val_loss: 0.0925 - val_tp: 236.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8429 - val_binary accuracy: 0.9756\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0803 - tp: 869.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9245 - binary accuracy: 0.9781 - val_loss: 0.0861 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0801 - tp: 865.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9202 - binary accuracy: 0.9774 - val_loss: 0.0840 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0771 - tp: 865.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9202 - binary accuracy: 0.9774 - val_loss: 0.0820 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0794 - tp: 864.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9290 - binary accuracy: 0.9781 - val_loss: 0.0852 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0790 - tp: 874.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9152 - binary accuracy: 0.9776 - val_loss: 0.1106 - val_tp: 238.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7604 - val_binary accuracy: 0.9654\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0782 - tp: 874.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9181 - binary accuracy: 0.9779 - val_loss: 0.0791 - val_tp: 232.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8923 - val_binary accuracy: 0.9797\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0795 - tp: 847.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9207 - binary accuracy: 0.9760 - val_loss: 0.0839 - val_tp: 233.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8598 - val_binary accuracy: 0.9766\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0793 - tp: 870.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9148 - binary accuracy: 0.9773 - val_loss: 0.0843 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0769 - tp: 861.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9101 - binary accuracy: 0.9762 - val_loss: 0.0918 - val_tp: 236.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8429 - val_binary accuracy: 0.9756\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0765 - tp: 869.0000 - tn: 10342.0000 - fp: 63.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9324 - binary accuracy: 0.9788 - val_loss: 0.0842 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0768 - tp: 874.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9190 - binary accuracy: 0.9780 - val_loss: 0.0888 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0787 - tp: 865.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9115 - binary accuracy: 0.9766 - val_loss: 0.0845 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0795 - tp: 877.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9164 - binary accuracy: 0.9780 - val_loss: 0.0832 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0809 - tp: 859.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9080 - binary accuracy: 0.9758 - val_loss: 0.0888 - val_tp: 236.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8489 - val_binary accuracy: 0.9763\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0804 - tp: 854.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9213 - binary accuracy: 0.9766 - val_loss: 0.0874 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0775 - tp: 873.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9317 - binary accuracy: 0.9790 - val_loss: 0.0926 - val_tp: 236.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8429 - val_binary accuracy: 0.9756\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0787 - tp: 868.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9195 - binary accuracy: 0.9776 - val_loss: 0.0831 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0774 - tp: 856.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9284 - binary accuracy: 0.9774 - val_loss: 0.1005 - val_tp: 237.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8034 - val_binary accuracy: 0.9710\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0769 - tp: 879.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9156 - binary accuracy: 0.9781 - val_loss: 0.0972 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0813 - tp: 863.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9280 - binary accuracy: 0.9779 - val_loss: 0.0864 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0769 - tp: 861.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9101 - binary accuracy: 0.9762 - val_loss: 0.1028 - val_tp: 238.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8068 - val_binary accuracy: 0.9717\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0770 - tp: 869.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9206 - binary accuracy: 0.9777 - val_loss: 0.0936 - val_tp: 236.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8459 - val_binary accuracy: 0.9759\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0788 - tp: 869.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9264 - binary accuracy: 0.9783 - val_loss: 0.1044 - val_tp: 238.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8041 - val_binary accuracy: 0.9714\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0762 - tp: 867.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9343 - binary accuracy: 0.9788 - val_loss: 0.0945 - val_tp: 236.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8520 - val_binary accuracy: 0.9766\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0784 - tp: 873.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9199 - binary accuracy: 0.9780 - val_loss: 0.0960 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0806 - tp: 855.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9263 - binary accuracy: 0.9771 - val_loss: 0.0956 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0763 - tp: 859.0000 - tn: 10343.0000 - fp: 62.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9327 - binary accuracy: 0.9780 - val_loss: 0.0943 - val_tp: 236.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8459 - val_binary accuracy: 0.9759\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0766 - tp: 884.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 165.0000 - recall: 0.8427 - precision: 0.9113 - binary accuracy: 0.9781 - val_loss: 0.1014 - val_tp: 237.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8061 - val_binary accuracy: 0.9714\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0783 - tp: 867.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9243 - binary accuracy: 0.9779 - val_loss: 0.0852 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0770 - tp: 862.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9239 - binary accuracy: 0.9775 - val_loss: 0.0837 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0778 - tp: 869.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9314 - binary accuracy: 0.9787 - val_loss: 0.0863 - val_tp: 233.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8694 - val_binary accuracy: 0.9777\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0781 - tp: 863.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9152 - binary accuracy: 0.9768 - val_loss: 0.1018 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0812 - tp: 835.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 214.0000 - recall: 0.7960 - precision: 0.9257 - binary accuracy: 0.9755 - val_loss: 0.0762 - val_tp: 227.0000 - val_tn: 2580.0000 - val_fp: 22.0000 - val_fn: 35.0000 - val_recall: 0.8664 - val_precision: 0.9116 - val_binary accuracy: 0.9801\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0785 - tp: 852.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9201 - binary accuracy: 0.9763 - val_loss: 0.1166 - val_tp: 239.0000 - val_tn: 2516.0000 - val_fp: 86.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7354 - val_binary accuracy: 0.9619\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0761 - tp: 877.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9145 - binary accuracy: 0.9778 - val_loss: 0.0841 - val_tp: 234.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8797 - val_binary accuracy: 0.9791\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0798 - tp: 848.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9288 - binary accuracy: 0.9768 - val_loss: 0.0952 - val_tp: 235.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8304 - val_binary accuracy: 0.9738\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.0783 - tp: 867.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9293 - binary accuracy: 0.9783 - val_loss: 0.1055 - val_tp: 239.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7967 - val_binary accuracy: 0.9707\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0774 - tp: 867.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9184 - binary accuracy: 0.9774 - val_loss: 0.0961 - val_tp: 236.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8339 - val_binary accuracy: 0.9745\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0761 - tp: 870.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9100 - binary accuracy: 0.9769 - val_loss: 0.0965 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0801 - tp: 843.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 206.0000 - recall: 0.8036 - precision: 0.9254 - binary accuracy: 0.9761 - val_loss: 0.0808 - val_tp: 233.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8927 - val_binary accuracy: 0.9801\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0759 - tp: 860.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9227 - binary accuracy: 0.9772 - val_loss: 0.0969 - val_tp: 237.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8201 - val_binary accuracy: 0.9731\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0750 - tp: 871.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9197 - binary accuracy: 0.9778 - val_loss: 0.0819 - val_tp: 234.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8797 - val_binary accuracy: 0.9791\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0766 - tp: 873.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9170 - binary accuracy: 0.9777 - val_loss: 0.0959 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0793 - tp: 866.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9232 - binary accuracy: 0.9777 - val_loss: 0.0878 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0766 - tp: 881.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 168.0000 - recall: 0.8398 - precision: 0.9254 - binary accuracy: 0.9791 - val_loss: 0.0976 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0776 - tp: 865.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9192 - binary accuracy: 0.9773 - val_loss: 0.0839 - val_tp: 234.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8864 - val_binary accuracy: 0.9797\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0773 - tp: 869.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9206 - binary accuracy: 0.9777 - val_loss: 0.1043 - val_tp: 237.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8089 - val_binary accuracy: 0.9717\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0761 - tp: 862.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9229 - binary accuracy: 0.9774 - val_loss: 0.0853 - val_tp: 234.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8699 - val_binary accuracy: 0.9780\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0784 - tp: 847.0000 - tn: 10346.0000 - fp: 59.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9349 - binary accuracy: 0.9772 - val_loss: 0.0900 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0814 - tp: 872.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9083 - binary accuracy: 0.9769 - val_loss: 0.1182 - val_tp: 239.0000 - val_tn: 2525.0000 - val_fp: 77.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7563 - val_binary accuracy: 0.9651\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0778 - tp: 873.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9228 - binary accuracy: 0.9783 - val_loss: 0.0830 - val_tp: 233.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8893 - val_binary accuracy: 0.9797\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0794 - tp: 850.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9239 - binary accuracy: 0.9765 - val_loss: 0.0844 - val_tp: 233.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8694 - val_binary accuracy: 0.9777\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0772 - tp: 862.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9279 - binary accuracy: 0.9778 - val_loss: 0.0892 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0808 - tp: 872.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9140 - binary accuracy: 0.9774 - val_loss: 0.1077 - val_tp: 237.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.8144 - val_binary accuracy: 0.9724\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0809 - tp: 854.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9124 - binary accuracy: 0.9758 - val_loss: 0.1153 - val_tp: 236.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7946 - val_binary accuracy: 0.9696\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0788 - tp: 866.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9232 - binary accuracy: 0.9777 - val_loss: 0.0938 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0798 - tp: 860.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9277 - binary accuracy: 0.9776 - val_loss: 0.1295 - val_tp: 238.0000 - val_tn: 2517.0000 - val_fp: 85.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7368 - val_binary accuracy: 0.9619\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0768 - tp: 864.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9221 - binary accuracy: 0.9775 - val_loss: 0.1030 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0776 - tp: 854.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9242 - binary accuracy: 0.9769 - val_loss: 0.0872 - val_tp: 234.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8731 - val_binary accuracy: 0.9784\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0791 - tp: 863.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9260 - binary accuracy: 0.9777 - val_loss: 0.0942 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0798 - tp: 848.0000 - tn: 10342.0000 - fp: 63.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9308 - binary accuracy: 0.9770 - val_loss: 0.0890 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0798 - tp: 872.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9228 - binary accuracy: 0.9782 - val_loss: 0.0884 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0794 - tp: 857.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9225 - binary accuracy: 0.9770 - val_loss: 0.0792 - val_tp: 231.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8851 - val_binary accuracy: 0.9787\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0754 - tp: 863.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9220 - binary accuracy: 0.9774 - val_loss: 0.0883 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0800 - tp: 870.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9197 - binary accuracy: 0.9777 - val_loss: 0.1039 - val_tp: 238.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8095 - val_binary accuracy: 0.9721\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0766 - tp: 880.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9283 - binary accuracy: 0.9793 - val_loss: 0.0969 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0797 - tp: 868.0000 - tn: 10319.0000 - fp: 86.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9099 - binary accuracy: 0.9767 - val_loss: 0.1176 - val_tp: 239.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7611 - val_binary accuracy: 0.9658\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0792 - tp: 857.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9176 - binary accuracy: 0.9765 - val_loss: 0.1137 - val_tp: 238.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7778 - val_binary accuracy: 0.9679\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0768 - tp: 866.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9164 - binary accuracy: 0.9771 - val_loss: 0.0971 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0790 - tp: 863.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9240 - binary accuracy: 0.9776 - val_loss: 0.0846 - val_tp: 234.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8699 - val_binary accuracy: 0.9780\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0781 - tp: 853.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9113 - binary accuracy: 0.9756 - val_loss: 0.0822 - val_tp: 232.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8755 - val_binary accuracy: 0.9780\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0779 - tp: 863.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9191 - binary accuracy: 0.9771 - val_loss: 0.0787 - val_tp: 232.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8889 - val_binary accuracy: 0.9794\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0767 - tp: 865.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9222 - binary accuracy: 0.9776 - val_loss: 0.0827 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0775 - tp: 863.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9240 - binary accuracy: 0.9776 - val_loss: 0.0868 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0801 - tp: 868.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9195 - binary accuracy: 0.9776 - val_loss: 0.0890 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0767 - tp: 864.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9182 - binary accuracy: 0.9771 - val_loss: 0.0831 - val_tp: 233.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8792 - val_binary accuracy: 0.9787\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0811 - tp: 861.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9189 - binary accuracy: 0.9770 - val_loss: 0.0893 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0787 - tp: 860.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9277 - binary accuracy: 0.9776 - val_loss: 0.0893 - val_tp: 233.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8630 - val_binary accuracy: 0.9770\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0736 - tp: 863.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9310 - binary accuracy: 0.9782 - val_loss: 0.1060 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0762 - tp: 866.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9242 - binary accuracy: 0.9778 - val_loss: 0.0933 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0792 - tp: 862.0000 - tn: 10315.0000 - fp: 90.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9055 - binary accuracy: 0.9758 - val_loss: 0.1050 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0803 - tp: 859.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9109 - binary accuracy: 0.9761 - val_loss: 0.0918 - val_tp: 233.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8535 - val_binary accuracy: 0.9759\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0760 - tp: 858.0000 - tn: 10347.0000 - fp: 58.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9367 - binary accuracy: 0.9783 - val_loss: 0.0931 - val_tp: 235.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8672 - val_binary accuracy: 0.9780\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0813 - tp: 865.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9251 - binary accuracy: 0.9778 - val_loss: 0.1057 - val_tp: 238.0000 - val_tn: 2536.0000 - val_fp: 66.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7829 - val_binary accuracy: 0.9686\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0760 - tp: 877.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9241 - binary accuracy: 0.9787 - val_loss: 0.0794 - val_tp: 231.0000 - val_tn: 2577.0000 - val_fp: 25.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.9023 - val_binary accuracy: 0.9804\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0817 - tp: 846.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 203.0000 - recall: 0.8065 - precision: 0.9216 - binary accuracy: 0.9760 - val_loss: 0.1058 - val_tp: 237.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7953 - val_binary accuracy: 0.9700\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0752 - tp: 879.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9166 - binary accuracy: 0.9782 - val_loss: 0.1005 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0771 - tp: 868.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9274 - binary accuracy: 0.9783 - val_loss: 0.0889 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0774 - tp: 865.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9134 - binary accuracy: 0.9768 - val_loss: 0.0924 - val_tp: 236.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8489 - val_binary accuracy: 0.9763\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0779 - tp: 869.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9264 - binary accuracy: 0.9783 - val_loss: 0.1058 - val_tp: 238.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8013 - val_binary accuracy: 0.9710\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0778 - tp: 856.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9175 - binary accuracy: 0.9764 - val_loss: 0.1009 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0787 - tp: 867.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9214 - binary accuracy: 0.9776 - val_loss: 0.0881 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0793 - tp: 867.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9175 - binary accuracy: 0.9773 - val_loss: 0.0881 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0779 - tp: 855.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9304 - binary accuracy: 0.9775 - val_loss: 0.0879 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0768 - tp: 869.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9186 - binary accuracy: 0.9776 - val_loss: 0.0850 - val_tp: 233.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8566 - val_binary accuracy: 0.9763\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0777 - tp: 854.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9283 - binary accuracy: 0.9772 - val_loss: 0.0772 - val_tp: 231.0000 - val_tn: 2578.0000 - val_fp: 24.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.9059 - val_binary accuracy: 0.9808\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0791 - tp: 873.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9219 - binary accuracy: 0.9782 - val_loss: 0.1140 - val_tp: 238.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7604 - val_binary accuracy: 0.9654\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0766 - tp: 864.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9182 - binary accuracy: 0.9771 - val_loss: 0.0847 - val_tp: 234.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8830 - val_binary accuracy: 0.9794\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0795 - tp: 860.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9338 - binary accuracy: 0.9782 - val_loss: 0.0940 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0769 - tp: 870.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9245 - binary accuracy: 0.9782 - val_loss: 0.0834 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0762 - tp: 863.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9210 - binary accuracy: 0.9773 - val_loss: 0.0864 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0773 - tp: 864.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9270 - binary accuracy: 0.9779 - val_loss: 0.0903 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0774 - tp: 870.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9226 - binary accuracy: 0.9780 - val_loss: 0.1110 - val_tp: 239.0000 - val_tn: 2534.0000 - val_fp: 68.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7785 - val_binary accuracy: 0.9682\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0798 - tp: 859.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9256 - binary accuracy: 0.9774 - val_loss: 0.1034 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0782 - tp: 851.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9220 - binary accuracy: 0.9764 - val_loss: 0.1063 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0784 - tp: 877.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 172.0000 - recall: 0.8360 - precision: 0.9193 - binary accuracy: 0.9783 - val_loss: 0.1140 - val_tp: 238.0000 - val_tn: 2533.0000 - val_fp: 69.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7752 - val_binary accuracy: 0.9675\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0786 - tp: 862.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9239 - binary accuracy: 0.9775 - val_loss: 0.0918 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0789 - tp: 856.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9155 - binary accuracy: 0.9763 - val_loss: 0.0959 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0785 - tp: 858.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9236 - binary accuracy: 0.9771 - val_loss: 0.0801 - val_tp: 232.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8923 - val_binary accuracy: 0.9797\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0773 - tp: 866.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9193 - binary accuracy: 0.9774 - val_loss: 0.0947 - val_tp: 236.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8429 - val_binary accuracy: 0.9756\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0771 - tp: 858.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9216 - binary accuracy: 0.9770 - val_loss: 0.0919 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0774 - tp: 879.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9262 - binary accuracy: 0.9790 - val_loss: 0.1016 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0756 - tp: 872.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9277 - binary accuracy: 0.9786 - val_loss: 0.1116 - val_tp: 236.0000 - val_tn: 2535.0000 - val_fp: 67.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7789 - val_binary accuracy: 0.9675\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0765 - tp: 866.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9232 - binary accuracy: 0.9777 - val_loss: 0.1018 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0790 - tp: 859.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9158 - binary accuracy: 0.9765 - val_loss: 0.0989 - val_tp: 236.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8339 - val_binary accuracy: 0.9745\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0765 - tp: 872.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9247 - binary accuracy: 0.9783 - val_loss: 0.0892 - val_tp: 234.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8699 - val_binary accuracy: 0.9780\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0774 - tp: 869.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9206 - binary accuracy: 0.9777 - val_loss: 0.1077 - val_tp: 238.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7881 - val_binary accuracy: 0.9693\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0770 - tp: 862.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9190 - binary accuracy: 0.9770 - val_loss: 0.0793 - val_tp: 232.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8992 - val_binary accuracy: 0.9804\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0776 - tp: 862.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9309 - binary accuracy: 0.9781 - val_loss: 0.0864 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0813 - tp: 868.0000 - tn: 10318.0000 - fp: 87.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9089 - binary accuracy: 0.9766 - val_loss: 0.1133 - val_tp: 239.0000 - val_tn: 2524.0000 - val_fp: 78.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7539 - val_binary accuracy: 0.9647\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0795 - tp: 865.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9144 - binary accuracy: 0.9769 - val_loss: 0.0797 - val_tp: 232.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8889 - val_binary accuracy: 0.9794\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0773 - tp: 866.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9292 - binary accuracy: 0.9783 - val_loss: 0.0929 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0801 - tp: 869.0000 - tn: 10317.0000 - fp: 88.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9080 - binary accuracy: 0.9766 - val_loss: 0.0919 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0773 - tp: 858.0000 - tn: 10349.0000 - fp: 56.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9387 - binary accuracy: 0.9784 - val_loss: 0.0777 - val_tp: 231.0000 - val_tn: 2576.0000 - val_fp: 26.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8988 - val_binary accuracy: 0.9801\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0772 - tp: 859.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9237 - binary accuracy: 0.9772 - val_loss: 0.1115 - val_tp: 239.0000 - val_tn: 2525.0000 - val_fp: 77.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7563 - val_binary accuracy: 0.9651\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0748 - tp: 870.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9226 - binary accuracy: 0.9780 - val_loss: 0.0814 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0777 - tp: 869.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9128 - binary accuracy: 0.9770 - val_loss: 0.0908 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0775 - tp: 878.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9203 - binary accuracy: 0.9784 - val_loss: 0.0798 - val_tp: 232.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8821 - val_binary accuracy: 0.9787\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0796 - tp: 855.0000 - tn: 10313.0000 - fp: 92.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9029 - binary accuracy: 0.9750 - val_loss: 0.0844 - val_tp: 233.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8694 - val_binary accuracy: 0.9777\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0744 - tp: 858.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9286 - binary accuracy: 0.9776 - val_loss: 0.0806 - val_tp: 233.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8893 - val_binary accuracy: 0.9797\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0771 - tp: 854.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9333 - binary accuracy: 0.9776 - val_loss: 0.0879 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0797 - tp: 864.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9241 - binary accuracy: 0.9776 - val_loss: 0.0914 - val_tp: 236.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8520 - val_binary accuracy: 0.9766\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0769 - tp: 879.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9175 - binary accuracy: 0.9783 - val_loss: 0.0987 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0798 - tp: 855.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9115 - binary accuracy: 0.9758 - val_loss: 0.0849 - val_tp: 234.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8764 - val_binary accuracy: 0.9787\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0790 - tp: 851.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9260 - binary accuracy: 0.9768 - val_loss: 0.1069 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0777 - tp: 867.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9243 - binary accuracy: 0.9779 - val_loss: 0.0903 - val_tp: 234.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8797 - val_binary accuracy: 0.9791\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0810 - tp: 857.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9225 - binary accuracy: 0.9770 - val_loss: 0.1081 - val_tp: 236.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8055 - val_binary accuracy: 0.9710\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0774 - tp: 863.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9191 - binary accuracy: 0.9771 - val_loss: 0.0955 - val_tp: 236.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8459 - val_binary accuracy: 0.9759\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0766 - tp: 865.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9173 - binary accuracy: 0.9771 - val_loss: 0.0888 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0771 - tp: 880.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9167 - binary accuracy: 0.9783 - val_loss: 0.0869 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0774 - tp: 860.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9237 - binary accuracy: 0.9773 - val_loss: 0.0808 - val_tp: 233.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8859 - val_binary accuracy: 0.9794\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0758 - tp: 862.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9299 - binary accuracy: 0.9780 - val_loss: 0.0974 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0770 - tp: 871.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9149 - binary accuracy: 0.9774 - val_loss: 0.1059 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0767 - tp: 872.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9277 - binary accuracy: 0.9786 - val_loss: 0.0963 - val_tp: 235.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8423 - val_binary accuracy: 0.9752\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0790 - tp: 865.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9173 - binary accuracy: 0.9771 - val_loss: 0.0966 - val_tp: 236.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8429 - val_binary accuracy: 0.9756\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0773 - tp: 858.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9256 - binary accuracy: 0.9773 - val_loss: 0.1045 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0782 - tp: 864.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9172 - binary accuracy: 0.9770 - val_loss: 0.0943 - val_tp: 236.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8429 - val_binary accuracy: 0.9756\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0776 - tp: 869.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9255 - binary accuracy: 0.9782 - val_loss: 0.0897 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0771 - tp: 860.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9159 - binary accuracy: 0.9766 - val_loss: 0.0835 - val_tp: 233.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8662 - val_binary accuracy: 0.9773\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0771 - tp: 857.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9336 - binary accuracy: 0.9779 - val_loss: 0.0810 - val_tp: 233.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8792 - val_binary accuracy: 0.9787\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0803 - tp: 862.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9151 - binary accuracy: 0.9767 - val_loss: 0.0876 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0757 - tp: 867.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9283 - binary accuracy: 0.9783 - val_loss: 0.0903 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0782 - tp: 865.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9261 - binary accuracy: 0.9779 - val_loss: 0.0975 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0800 - tp: 857.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9245 - binary accuracy: 0.9771 - val_loss: 0.0863 - val_tp: 234.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8764 - val_binary accuracy: 0.9787\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0776 - tp: 869.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9264 - binary accuracy: 0.9783 - val_loss: 0.0958 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0784 - tp: 865.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9163 - binary accuracy: 0.9770 - val_loss: 0.0908 - val_tp: 236.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8551 - val_binary accuracy: 0.9770\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0778 - tp: 867.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9146 - binary accuracy: 0.9770 - val_loss: 0.0871 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0782 - tp: 848.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9329 - binary accuracy: 0.9771 - val_loss: 0.0977 - val_tp: 236.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8339 - val_binary accuracy: 0.9745\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0803 - tp: 859.0000 - tn: 10314.0000 - fp: 91.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9042 - binary accuracy: 0.9755 - val_loss: 0.1144 - val_tp: 238.0000 - val_tn: 2533.0000 - val_fp: 69.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7752 - val_binary accuracy: 0.9675\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0771 - tp: 860.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9198 - binary accuracy: 0.9770 - val_loss: 0.0925 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0789 - tp: 848.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9217 - binary accuracy: 0.9762 - val_loss: 0.0934 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0788 - tp: 870.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9187 - binary accuracy: 0.9776 - val_loss: 0.0841 - val_tp: 234.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8699 - val_binary accuracy: 0.9780\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0747 - tp: 866.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9232 - binary accuracy: 0.9777 - val_loss: 0.1074 - val_tp: 238.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7881 - val_binary accuracy: 0.9693\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0787 - tp: 853.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9094 - binary accuracy: 0.9755 - val_loss: 0.0880 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0784 - tp: 858.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9236 - binary accuracy: 0.9771 - val_loss: 0.0831 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0780 - tp: 860.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9257 - binary accuracy: 0.9775 - val_loss: 0.1005 - val_tp: 236.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8000 - val_binary accuracy: 0.9703\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0781 - tp: 863.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9270 - binary accuracy: 0.9778 - val_loss: 0.0937 - val_tp: 235.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8453 - val_binary accuracy: 0.9756\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0770 - tp: 860.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9208 - binary accuracy: 0.9770 - val_loss: 0.0968 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0783 - tp: 866.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9232 - binary accuracy: 0.9777 - val_loss: 0.1181 - val_tp: 238.0000 - val_tn: 2529.0000 - val_fp: 73.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7653 - val_binary accuracy: 0.9661\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0789 - tp: 869.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9157 - binary accuracy: 0.9773 - val_loss: 0.0889 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0761 - tp: 847.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9247 - binary accuracy: 0.9763 - val_loss: 0.1120 - val_tp: 238.0000 - val_tn: 2533.0000 - val_fp: 69.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7752 - val_binary accuracy: 0.9675\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0794 - tp: 857.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9275 - binary accuracy: 0.9774 - val_loss: 0.0912 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0767 - tp: 853.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9232 - binary accuracy: 0.9767 - val_loss: 0.1006 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0773 - tp: 856.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9234 - binary accuracy: 0.9770 - val_loss: 0.0871 - val_tp: 234.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8830 - val_binary accuracy: 0.9794\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0790 - tp: 854.0000 - tn: 10342.0000 - fp: 63.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9313 - binary accuracy: 0.9775 - val_loss: 0.0958 - val_tp: 235.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8453 - val_binary accuracy: 0.9756\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0786 - tp: 871.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9159 - binary accuracy: 0.9775 - val_loss: 0.1138 - val_tp: 237.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7874 - val_binary accuracy: 0.9689\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0785 - tp: 864.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9172 - binary accuracy: 0.9770 - val_loss: 0.0896 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0790 - tp: 857.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9255 - binary accuracy: 0.9772 - val_loss: 0.0821 - val_tp: 233.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8826 - val_binary accuracy: 0.9791\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0762 - tp: 873.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9122 - binary accuracy: 0.9773 - val_loss: 0.1041 - val_tp: 236.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8027 - val_binary accuracy: 0.9707\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0802 - tp: 869.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9147 - binary accuracy: 0.9772 - val_loss: 0.0985 - val_tp: 235.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8393 - val_binary accuracy: 0.9749\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0797 - tp: 854.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9163 - binary accuracy: 0.9762 - val_loss: 0.0915 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0761 - tp: 856.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9224 - binary accuracy: 0.9769 - val_loss: 0.0878 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0756 - tp: 868.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9254 - binary accuracy: 0.9781 - val_loss: 0.0899 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0786 - tp: 870.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9197 - binary accuracy: 0.9777 - val_loss: 0.0967 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0773 - tp: 866.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9213 - binary accuracy: 0.9776 - val_loss: 0.0946 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0769 - tp: 855.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9263 - binary accuracy: 0.9771 - val_loss: 0.0834 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0765 - tp: 864.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9251 - binary accuracy: 0.9777 - val_loss: 0.0854 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0766 - tp: 845.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 204.0000 - recall: 0.8055 - precision: 0.9265 - binary accuracy: 0.9763 - val_loss: 0.0783 - val_tp: 232.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8958 - val_binary accuracy: 0.9801\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0780 - tp: 868.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9293 - binary accuracy: 0.9784 - val_loss: 0.1056 - val_tp: 236.0000 - val_tn: 2540.0000 - val_fp: 62.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7919 - val_binary accuracy: 0.9693\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0787 - tp: 859.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9197 - binary accuracy: 0.9769 - val_loss: 0.0928 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0812 - tp: 871.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9140 - binary accuracy: 0.9773 - val_loss: 0.0979 - val_tp: 235.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8275 - val_binary accuracy: 0.9735\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0766 - tp: 872.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9237 - binary accuracy: 0.9783 - val_loss: 0.1061 - val_tp: 236.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8110 - val_binary accuracy: 0.9717\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0759 - tp: 865.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9192 - binary accuracy: 0.9773 - val_loss: 0.0903 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0764 - tp: 861.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9238 - binary accuracy: 0.9774 - val_loss: 0.0835 - val_tp: 235.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8672 - val_binary accuracy: 0.9780\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0761 - tp: 867.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9253 - binary accuracy: 0.9780 - val_loss: 0.0829 - val_tp: 232.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8657 - val_binary accuracy: 0.9770\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0781 - tp: 859.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9177 - binary accuracy: 0.9767 - val_loss: 0.0843 - val_tp: 233.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8662 - val_binary accuracy: 0.9773\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0779 - tp: 859.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9247 - binary accuracy: 0.9773 - val_loss: 0.0907 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0778 - tp: 865.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9311 - binary accuracy: 0.9783 - val_loss: 0.0917 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0773 - tp: 866.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9282 - binary accuracy: 0.9782 - val_loss: 0.0912 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0795 - tp: 866.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9164 - binary accuracy: 0.9771 - val_loss: 0.0912 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0766 - tp: 857.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9176 - binary accuracy: 0.9765 - val_loss: 0.1045 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0799 - tp: 861.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9258 - binary accuracy: 0.9776 - val_loss: 0.0887 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0771 - tp: 864.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9211 - binary accuracy: 0.9774 - val_loss: 0.0862 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0768 - tp: 863.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9240 - binary accuracy: 0.9776 - val_loss: 0.0923 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0768 - tp: 860.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9257 - binary accuracy: 0.9775 - val_loss: 0.0852 - val_tp: 233.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8630 - val_binary accuracy: 0.9770\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0785 - tp: 854.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9183 - binary accuracy: 0.9763 - val_loss: 0.0909 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0774 - tp: 862.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9170 - binary accuracy: 0.9769 - val_loss: 0.0878 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0795 - tp: 856.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9264 - binary accuracy: 0.9772 - val_loss: 0.1031 - val_tp: 236.0000 - val_tn: 2545.0000 - val_fp: 57.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8055 - val_binary accuracy: 0.9710\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0762 - tp: 873.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 176.0000 - recall: 0.8322 - precision: 0.9258 - binary accuracy: 0.9785 - val_loss: 0.0957 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0774 - tp: 851.0000 - tn: 10342.0000 - fp: 63.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9311 - binary accuracy: 0.9772 - val_loss: 0.0798 - val_tp: 232.0000 - val_tn: 2575.0000 - val_fp: 27.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8958 - val_binary accuracy: 0.9801\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0773 - tp: 866.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9145 - binary accuracy: 0.9770 - val_loss: 0.0892 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0800 - tp: 870.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9168 - binary accuracy: 0.9775 - val_loss: 0.0811 - val_tp: 233.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8893 - val_binary accuracy: 0.9797\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0762 - tp: 868.0000 - tn: 10342.0000 - fp: 63.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9323 - binary accuracy: 0.9787 - val_loss: 0.0947 - val_tp: 236.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8429 - val_binary accuracy: 0.9756\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0763 - tp: 866.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9242 - binary accuracy: 0.9778 - val_loss: 0.0871 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0791 - tp: 850.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9259 - binary accuracy: 0.9767 - val_loss: 0.0961 - val_tp: 235.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8363 - val_binary accuracy: 0.9745\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0789 - tp: 872.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9160 - binary accuracy: 0.9776 - val_loss: 0.1293 - val_tp: 240.0000 - val_tn: 2520.0000 - val_fp: 82.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7453 - val_binary accuracy: 0.9637\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0770 - tp: 860.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9198 - binary accuracy: 0.9770 - val_loss: 0.0802 - val_tp: 232.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8889 - val_binary accuracy: 0.9794\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0756 - tp: 847.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9297 - binary accuracy: 0.9768 - val_loss: 0.0790 - val_tp: 232.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 30.0000 - val_recall: 0.8855 - val_precision: 0.8821 - val_binary accuracy: 0.9787\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0777 - tp: 858.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9216 - binary accuracy: 0.9770 - val_loss: 0.0806 - val_tp: 233.0000 - val_tn: 2570.0000 - val_fp: 32.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8792 - val_binary accuracy: 0.9787\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0774 - tp: 872.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9189 - binary accuracy: 0.9778 - val_loss: 0.0825 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0773 - tp: 849.0000 - tn: 10349.0000 - fp: 56.0000 - fn: 200.0000 - recall: 0.8093 - precision: 0.9381 - binary accuracy: 0.9776 - val_loss: 0.0957 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0791 - tp: 863.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9113 - binary accuracy: 0.9764 - val_loss: 0.0915 - val_tp: 236.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8489 - val_binary accuracy: 0.9763\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0770 - tp: 867.0000 - tn: 10342.0000 - fp: 63.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9323 - binary accuracy: 0.9786 - val_loss: 0.0828 - val_tp: 233.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8662 - val_binary accuracy: 0.9773\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0783 - tp: 866.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9262 - binary accuracy: 0.9780 - val_loss: 0.0877 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0762 - tp: 867.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9273 - binary accuracy: 0.9782 - val_loss: 0.0876 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0809 - tp: 853.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9212 - binary accuracy: 0.9765 - val_loss: 0.0956 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0787 - tp: 862.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9180 - binary accuracy: 0.9770 - val_loss: 0.0826 - val_tp: 234.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8764 - val_binary accuracy: 0.9787\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0789 - tp: 849.0000 - tn: 10345.0000 - fp: 60.0000 - fn: 200.0000 - recall: 0.8093 - precision: 0.9340 - binary accuracy: 0.9773 - val_loss: 0.0910 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0757 - tp: 876.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 173.0000 - recall: 0.8351 - precision: 0.9280 - binary accuracy: 0.9790 - val_loss: 0.0905 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0783 - tp: 859.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9207 - binary accuracy: 0.9770 - val_loss: 0.0920 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0759 - tp: 859.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9307 - binary accuracy: 0.9778 - val_loss: 0.0947 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0775 - tp: 854.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9252 - binary accuracy: 0.9770 - val_loss: 0.1065 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0758 - tp: 865.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9271 - binary accuracy: 0.9780 - val_loss: 0.1137 - val_tp: 236.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.7973 - val_binary accuracy: 0.9700\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0763 - tp: 880.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 169.0000 - recall: 0.8389 - precision: 0.9148 - binary accuracy: 0.9781 - val_loss: 0.0995 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0793 - tp: 869.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9235 - binary accuracy: 0.9780 - val_loss: 0.0958 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0772 - tp: 861.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9248 - binary accuracy: 0.9775 - val_loss: 0.1048 - val_tp: 236.0000 - val_tn: 2546.0000 - val_fp: 56.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8082 - val_binary accuracy: 0.9714\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0780 - tp: 865.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9173 - binary accuracy: 0.9771 - val_loss: 0.1058 - val_tp: 236.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8000 - val_binary accuracy: 0.9703\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0773 - tp: 866.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9223 - binary accuracy: 0.9776 - val_loss: 0.1256 - val_tp: 239.0000 - val_tn: 2520.0000 - val_fp: 82.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7445 - val_binary accuracy: 0.9633\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0791 - tp: 872.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9179 - binary accuracy: 0.9777 - val_loss: 0.0970 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0772 - tp: 866.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9342 - binary accuracy: 0.9787 - val_loss: 0.0881 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0782 - tp: 845.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 204.0000 - recall: 0.8055 - precision: 0.9296 - binary accuracy: 0.9766 - val_loss: 0.0947 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0781 - tp: 862.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9180 - binary accuracy: 0.9770 - val_loss: 0.1069 - val_tp: 238.0000 - val_tn: 2533.0000 - val_fp: 69.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7752 - val_binary accuracy: 0.9675\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0785 - tp: 867.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9175 - binary accuracy: 0.9773 - val_loss: 0.0944 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0780 - tp: 853.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 196.0000 - recall: 0.8132 - precision: 0.9212 - binary accuracy: 0.9765 - val_loss: 0.1135 - val_tp: 238.0000 - val_tn: 2527.0000 - val_fp: 75.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7604 - val_binary accuracy: 0.9654\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0785 - tp: 854.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9222 - binary accuracy: 0.9767 - val_loss: 0.0931 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0785 - tp: 859.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9207 - binary accuracy: 0.9770 - val_loss: 0.0863 - val_tp: 235.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8640 - val_binary accuracy: 0.9777\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0771 - tp: 874.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9308 - binary accuracy: 0.9790 - val_loss: 0.0917 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0804 - tp: 872.0000 - tn: 10312.0000 - fp: 93.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9036 - binary accuracy: 0.9764 - val_loss: 0.0987 - val_tp: 236.0000 - val_tn: 2552.0000 - val_fp: 50.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8252 - val_binary accuracy: 0.9735\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0789 - tp: 848.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9227 - binary accuracy: 0.9763 - val_loss: 0.0881 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0813 - tp: 847.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9217 - binary accuracy: 0.9761 - val_loss: 0.0948 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0798 - tp: 856.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9194 - binary accuracy: 0.9766 - val_loss: 0.0993 - val_tp: 238.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8041 - val_binary accuracy: 0.9714\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0786 - tp: 863.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9240 - binary accuracy: 0.9776 - val_loss: 0.0868 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0760 - tp: 865.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9241 - binary accuracy: 0.9777 - val_loss: 0.0958 - val_tp: 236.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8459 - val_binary accuracy: 0.9759\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0782 - tp: 851.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9230 - binary accuracy: 0.9765 - val_loss: 0.0949 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0762 - tp: 866.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9183 - binary accuracy: 0.9773 - val_loss: 0.0907 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0781 - tp: 857.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9235 - binary accuracy: 0.9770 - val_loss: 0.0849 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0774 - tp: 871.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9236 - binary accuracy: 0.9782 - val_loss: 0.0855 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0792 - tp: 841.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 208.0000 - recall: 0.8017 - precision: 0.9272 - binary accuracy: 0.9761 - val_loss: 0.0814 - val_tp: 233.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8826 - val_binary accuracy: 0.9791\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0781 - tp: 863.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9220 - binary accuracy: 0.9774 - val_loss: 0.0964 - val_tp: 238.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8207 - val_binary accuracy: 0.9735\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0763 - tp: 860.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9267 - binary accuracy: 0.9776 - val_loss: 0.0819 - val_tp: 233.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8826 - val_binary accuracy: 0.9791\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0779 - tp: 855.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9203 - binary accuracy: 0.9766 - val_loss: 0.0984 - val_tp: 236.0000 - val_tn: 2550.0000 - val_fp: 52.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8194 - val_binary accuracy: 0.9728\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0811 - tp: 863.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9220 - binary accuracy: 0.9774 - val_loss: 0.0943 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0782 - tp: 857.0000 - tn: 10320.0000 - fp: 85.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9098 - binary accuracy: 0.9758 - val_loss: 0.1098 - val_tp: 238.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7960 - val_binary accuracy: 0.9703\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0794 - tp: 872.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9150 - binary accuracy: 0.9775 - val_loss: 0.1070 - val_tp: 238.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7960 - val_binary accuracy: 0.9703\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0753 - tp: 860.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9287 - binary accuracy: 0.9777 - val_loss: 0.0875 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0752 - tp: 861.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9278 - binary accuracy: 0.9777 - val_loss: 0.0949 - val_tp: 236.0000 - val_tn: 2555.0000 - val_fp: 47.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8339 - val_binary accuracy: 0.9745\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0788 - tp: 854.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9222 - binary accuracy: 0.9767 - val_loss: 0.0862 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0771 - tp: 870.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9187 - binary accuracy: 0.9776 - val_loss: 0.0807 - val_tp: 233.0000 - val_tn: 2574.0000 - val_fp: 28.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8927 - val_binary accuracy: 0.9801\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0797 - tp: 851.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 198.0000 - recall: 0.8112 - precision: 0.9131 - binary accuracy: 0.9756 - val_loss: 0.0792 - val_tp: 233.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8859 - val_binary accuracy: 0.9794\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0769 - tp: 867.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9214 - binary accuracy: 0.9776 - val_loss: 0.0829 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0784 - tp: 861.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9160 - binary accuracy: 0.9767 - val_loss: 0.0923 - val_tp: 235.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8453 - val_binary accuracy: 0.9756\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0792 - tp: 855.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9184 - binary accuracy: 0.9764 - val_loss: 0.0840 - val_tp: 234.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8764 - val_binary accuracy: 0.9787\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0805 - tp: 848.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9177 - binary accuracy: 0.9758 - val_loss: 0.1026 - val_tp: 236.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8138 - val_binary accuracy: 0.9721\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0777 - tp: 860.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9178 - binary accuracy: 0.9768 - val_loss: 0.0933 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0783 - tp: 867.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9293 - binary accuracy: 0.9783 - val_loss: 0.0994 - val_tp: 235.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8393 - val_binary accuracy: 0.9749\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0777 - tp: 852.0000 - tn: 10345.0000 - fp: 60.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9342 - binary accuracy: 0.9776 - val_loss: 0.1243 - val_tp: 239.0000 - val_tn: 2538.0000 - val_fp: 64.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7888 - val_binary accuracy: 0.9696\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0772 - tp: 861.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9248 - binary accuracy: 0.9775 - val_loss: 0.1026 - val_tp: 235.0000 - val_tn: 2553.0000 - val_fp: 49.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8275 - val_binary accuracy: 0.9735\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0761 - tp: 859.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9256 - binary accuracy: 0.9774 - val_loss: 0.0954 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0751 - tp: 867.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9243 - binary accuracy: 0.9779 - val_loss: 0.0963 - val_tp: 235.0000 - val_tn: 2559.0000 - val_fp: 43.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8453 - val_binary accuracy: 0.9756\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0785 - tp: 854.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 195.0000 - recall: 0.8141 - precision: 0.9273 - binary accuracy: 0.9771 - val_loss: 0.0882 - val_tp: 235.0000 - val_tn: 2567.0000 - val_fp: 35.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8704 - val_binary accuracy: 0.9784\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0767 - tp: 863.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9123 - binary accuracy: 0.9765 - val_loss: 0.0954 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0773 - tp: 847.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 202.0000 - recall: 0.8074 - precision: 0.9328 - binary accuracy: 0.9770 - val_loss: 0.0877 - val_tp: 234.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8897 - val_binary accuracy: 0.9801\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0773 - tp: 866.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9223 - binary accuracy: 0.9776 - val_loss: 0.1284 - val_tp: 240.0000 - val_tn: 2516.0000 - val_fp: 86.0000 - val_fn: 22.0000 - val_recall: 0.9160 - val_precision: 0.7362 - val_binary accuracy: 0.9623\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0779 - tp: 883.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 166.0000 - recall: 0.8418 - precision: 0.9208 - binary accuracy: 0.9789 - val_loss: 0.0909 - val_tp: 234.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8667 - val_binary accuracy: 0.9777\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0769 - tp: 872.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 177.0000 - recall: 0.8313 - precision: 0.9277 - binary accuracy: 0.9786 - val_loss: 0.1043 - val_tp: 236.0000 - val_tn: 2551.0000 - val_fp: 51.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8223 - val_binary accuracy: 0.9731\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0782 - tp: 850.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9219 - binary accuracy: 0.9763 - val_loss: 0.1043 - val_tp: 238.0000 - val_tn: 2548.0000 - val_fp: 54.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8151 - val_binary accuracy: 0.9728\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0780 - tp: 864.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9143 - binary accuracy: 0.9768 - val_loss: 0.0914 - val_tp: 235.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8484 - val_binary accuracy: 0.9759\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0776 - tp: 860.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9257 - binary accuracy: 0.9775 - val_loss: 0.0871 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0792 - tp: 859.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9168 - binary accuracy: 0.9766 - val_loss: 0.0851 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0754 - tp: 871.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9227 - binary accuracy: 0.9781 - val_loss: 0.0926 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0794 - tp: 856.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9244 - binary accuracy: 0.9770 - val_loss: 0.0817 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0773 - tp: 869.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9138 - binary accuracy: 0.9771 - val_loss: 0.0999 - val_tp: 238.0000 - val_tn: 2541.0000 - val_fp: 61.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7960 - val_binary accuracy: 0.9703\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0799 - tp: 862.0000 - tn: 10322.0000 - fp: 83.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9122 - binary accuracy: 0.9764 - val_loss: 0.0843 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0787 - tp: 860.0000 - tn: 10331.0000 - fp: 74.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9208 - binary accuracy: 0.9770 - val_loss: 0.0939 - val_tp: 236.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8551 - val_binary accuracy: 0.9770\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0763 - tp: 849.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 200.0000 - recall: 0.8093 - precision: 0.9269 - binary accuracy: 0.9767 - val_loss: 0.0976 - val_tp: 236.0000 - val_tn: 2558.0000 - val_fp: 44.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8429 - val_binary accuracy: 0.9756\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0761 - tp: 863.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9240 - binary accuracy: 0.9776 - val_loss: 0.1119 - val_tp: 238.0000 - val_tn: 2542.0000 - val_fp: 60.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.7987 - val_binary accuracy: 0.9707\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0764 - tp: 869.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9225 - binary accuracy: 0.9779 - val_loss: 0.1093 - val_tp: 236.0000 - val_tn: 2549.0000 - val_fp: 53.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8166 - val_binary accuracy: 0.9724\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0757 - tp: 855.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9253 - binary accuracy: 0.9770 - val_loss: 0.1030 - val_tp: 238.0000 - val_tn: 2547.0000 - val_fp: 55.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8123 - val_binary accuracy: 0.9724\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0767 - tp: 867.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 182.0000 - recall: 0.8265 - precision: 0.9273 - binary accuracy: 0.9782 - val_loss: 0.1020 - val_tp: 236.0000 - val_tn: 2543.0000 - val_fp: 59.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8000 - val_binary accuracy: 0.9703\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0766 - tp: 858.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9196 - binary accuracy: 0.9768 - val_loss: 0.0960 - val_tp: 236.0000 - val_tn: 2557.0000 - val_fp: 45.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8399 - val_binary accuracy: 0.9752\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0755 - tp: 870.0000 - tn: 10341.0000 - fp: 64.0000 - fn: 179.0000 - recall: 0.8294 - precision: 0.9315 - binary accuracy: 0.9788 - val_loss: 0.0902 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0783 - tp: 848.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 201.0000 - recall: 0.8084 - precision: 0.9187 - binary accuracy: 0.9759 - val_loss: 0.0866 - val_tp: 235.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8672 - val_binary accuracy: 0.9780\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0781 - tp: 871.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 178.0000 - recall: 0.8303 - precision: 0.9266 - binary accuracy: 0.9784 - val_loss: 0.0843 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0782 - tp: 862.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9170 - binary accuracy: 0.9769 - val_loss: 0.0793 - val_tp: 233.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8826 - val_binary accuracy: 0.9791\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0783 - tp: 856.0000 - tn: 10326.0000 - fp: 79.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9155 - binary accuracy: 0.9763 - val_loss: 0.0832 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0794 - tp: 844.0000 - tn: 10337.0000 - fp: 68.0000 - fn: 205.0000 - recall: 0.8046 - precision: 0.9254 - binary accuracy: 0.9762 - val_loss: 0.0888 - val_tp: 235.0000 - val_tn: 2566.0000 - val_fp: 36.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8672 - val_binary accuracy: 0.9780\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0755 - tp: 852.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 197.0000 - recall: 0.8122 - precision: 0.9281 - binary accuracy: 0.9770 - val_loss: 0.1138 - val_tp: 239.0000 - val_tn: 2523.0000 - val_fp: 79.0000 - val_fn: 23.0000 - val_recall: 0.9122 - val_precision: 0.7516 - val_binary accuracy: 0.9644\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0780 - tp: 869.0000 - tn: 10327.0000 - fp: 78.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9176 - binary accuracy: 0.9775 - val_loss: 0.0816 - val_tp: 233.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8859 - val_binary accuracy: 0.9794\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0774 - tp: 856.0000 - tn: 10347.0000 - fp: 58.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9365 - binary accuracy: 0.9781 - val_loss: 0.0854 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0782 - tp: 855.0000 - tn: 10328.0000 - fp: 77.0000 - fn: 194.0000 - recall: 0.8151 - precision: 0.9174 - binary accuracy: 0.9763 - val_loss: 0.0834 - val_tp: 233.0000 - val_tn: 2568.0000 - val_fp: 34.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8727 - val_binary accuracy: 0.9780\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0756 - tp: 858.0000 - tn: 10340.0000 - fp: 65.0000 - fn: 191.0000 - recall: 0.8179 - precision: 0.9296 - binary accuracy: 0.9776 - val_loss: 0.0923 - val_tp: 236.0000 - val_tn: 2560.0000 - val_fp: 42.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8489 - val_binary accuracy: 0.9763\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0770 - tp: 850.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9229 - binary accuracy: 0.9764 - val_loss: 0.0829 - val_tp: 233.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8826 - val_binary accuracy: 0.9791\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0759 - tp: 869.0000 - tn: 10339.0000 - fp: 66.0000 - fn: 180.0000 - recall: 0.8284 - precision: 0.9294 - binary accuracy: 0.9785 - val_loss: 0.1186 - val_tp: 237.0000 - val_tn: 2521.0000 - val_fp: 81.0000 - val_fn: 25.0000 - val_recall: 0.9046 - val_precision: 0.7453 - val_binary accuracy: 0.9630\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0792 - tp: 868.0000 - tn: 10333.0000 - fp: 72.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9234 - binary accuracy: 0.9779 - val_loss: 0.0981 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0800 - tp: 856.0000 - tn: 10343.0000 - fp: 62.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9325 - binary accuracy: 0.9777 - val_loss: 0.0945 - val_tp: 235.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8608 - val_binary accuracy: 0.9773\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0796 - tp: 856.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9185 - binary accuracy: 0.9765 - val_loss: 0.1031 - val_tp: 236.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8027 - val_binary accuracy: 0.9707\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0798 - tp: 868.0000 - tn: 10321.0000 - fp: 84.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9118 - binary accuracy: 0.9769 - val_loss: 0.0860 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0744 - tp: 868.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 181.0000 - recall: 0.8275 - precision: 0.9254 - binary accuracy: 0.9781 - val_loss: 0.1068 - val_tp: 238.0000 - val_tn: 2544.0000 - val_fp: 58.0000 - val_fn: 24.0000 - val_recall: 0.9084 - val_precision: 0.8041 - val_binary accuracy: 0.9714\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0804 - tp: 862.0000 - tn: 10324.0000 - fp: 81.0000 - fn: 187.0000 - recall: 0.8217 - precision: 0.9141 - binary accuracy: 0.9766 - val_loss: 0.0825 - val_tp: 231.0000 - val_tn: 2571.0000 - val_fp: 31.0000 - val_fn: 31.0000 - val_recall: 0.8817 - val_precision: 0.8817 - val_binary accuracy: 0.9784\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0770 - tp: 859.0000 - tn: 10338.0000 - fp: 67.0000 - fn: 190.0000 - recall: 0.8189 - precision: 0.9276 - binary accuracy: 0.9776 - val_loss: 0.0935 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0778 - tp: 857.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 192.0000 - recall: 0.8170 - precision: 0.9146 - binary accuracy: 0.9763 - val_loss: 0.0875 - val_tp: 234.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8603 - val_binary accuracy: 0.9770\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0790 - tp: 850.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 199.0000 - recall: 0.8103 - precision: 0.9179 - binary accuracy: 0.9760 - val_loss: 0.0975 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0792 - tp: 856.0000 - tn: 10329.0000 - fp: 76.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9185 - binary accuracy: 0.9765 - val_loss: 0.0872 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0770 - tp: 856.0000 - tn: 10342.0000 - fp: 63.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9314 - binary accuracy: 0.9776 - val_loss: 0.0827 - val_tp: 233.0000 - val_tn: 2573.0000 - val_fp: 29.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8893 - val_binary accuracy: 0.9797\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0788 - tp: 865.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 184.0000 - recall: 0.8246 - precision: 0.9202 - binary accuracy: 0.9774 - val_loss: 0.0890 - val_tp: 235.0000 - val_tn: 2561.0000 - val_fp: 41.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8514 - val_binary accuracy: 0.9763\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 0.0757 - tp: 874.0000 - tn: 10335.0000 - fp: 70.0000 - fn: 175.0000 - recall: 0.8332 - precision: 0.9258 - binary accuracy: 0.9786 - val_loss: 0.0801 - val_tp: 233.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8859 - val_binary accuracy: 0.9794\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0772 - tp: 861.0000 - tn: 10332.0000 - fp: 73.0000 - fn: 188.0000 - recall: 0.8208 - precision: 0.9218 - binary accuracy: 0.9772 - val_loss: 0.0886 - val_tp: 233.0000 - val_tn: 2564.0000 - val_fp: 38.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8598 - val_binary accuracy: 0.9766\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0792 - tp: 856.0000 - tn: 10330.0000 - fp: 75.0000 - fn: 193.0000 - recall: 0.8160 - precision: 0.9194 - binary accuracy: 0.9766 - val_loss: 0.0969 - val_tp: 236.0000 - val_tn: 2556.0000 - val_fp: 46.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8369 - val_binary accuracy: 0.9749\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0790 - tp: 860.0000 - tn: 10334.0000 - fp: 71.0000 - fn: 189.0000 - recall: 0.8198 - precision: 0.9237 - binary accuracy: 0.9773 - val_loss: 0.0877 - val_tp: 234.0000 - val_tn: 2565.0000 - val_fp: 37.0000 - val_fn: 28.0000 - val_recall: 0.8931 - val_precision: 0.8635 - val_binary accuracy: 0.9773\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0768 - tp: 866.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 183.0000 - recall: 0.8255 - precision: 0.9154 - binary accuracy: 0.9770 - val_loss: 0.0906 - val_tp: 235.0000 - val_tn: 2562.0000 - val_fp: 40.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8545 - val_binary accuracy: 0.9766\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0762 - tp: 878.0000 - tn: 10325.0000 - fp: 80.0000 - fn: 171.0000 - recall: 0.8370 - precision: 0.9165 - binary accuracy: 0.9781 - val_loss: 0.0817 - val_tp: 233.0000 - val_tn: 2569.0000 - val_fp: 33.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8759 - val_binary accuracy: 0.9784\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0771 - tp: 863.0000 - tn: 10336.0000 - fp: 69.0000 - fn: 186.0000 - recall: 0.8227 - precision: 0.9260 - binary accuracy: 0.9777 - val_loss: 0.0848 - val_tp: 235.0000 - val_tn: 2563.0000 - val_fp: 39.0000 - val_fn: 27.0000 - val_recall: 0.8969 - val_precision: 0.8577 - val_binary accuracy: 0.9770\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0791 - tp: 864.0000 - tn: 10323.0000 - fp: 82.0000 - fn: 185.0000 - recall: 0.8236 - precision: 0.9133 - binary accuracy: 0.9767 - val_loss: 0.0964 - val_tp: 236.0000 - val_tn: 2554.0000 - val_fp: 48.0000 - val_fn: 26.0000 - val_recall: 0.9008 - val_precision: 0.8310 - val_binary accuracy: 0.9742\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0735 - tp: 879.0000 - tn: 10344.0000 - fp: 61.0000 - fn: 170.0000 - recall: 0.8379 - precision: 0.9351 - binary accuracy: 0.9798 - val_loss: 0.0816 - val_tp: 233.0000 - val_tn: 2572.0000 - val_fp: 30.0000 - val_fn: 29.0000 - val_recall: 0.8893 - val_precision: 0.8859 - val_binary accuracy: 0.9794\n",
            "112/112 - 0s - loss: 0.0813 - tp: 296.0000 - tn: 3208.0000 - fp: 44.0000 - fn: 32.0000 - recall: 0.9024 - precision: 0.8706 - binary accuracy: 0.9788 - 427ms/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08132930845022202,\n",
              " 296.0,\n",
              " 3208.0,\n",
              " 44.0,\n",
              " 32.0,\n",
              " 0.9024389982223511,\n",
              " 0.8705882430076599,\n",
              " 0.9787709712982178]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "y_test_pred = (y_test_pred > 0.5).astype(np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rLngcXKvn4N",
        "outputId": "d6af2b28-7237-4adb-b925-f7b8ec60b743"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "cm = pd.DataFrame(cm)\n",
        "cm.columns = ['Predicted 0', 'Predicted 1']\n",
        "cm.rename(index={0: \"True 0\", 1: \"True 1\"}, inplace = True)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "iwHPcW5swQY0",
        "outputId": "88f7b860-2839-4162-8431-b637f87bafb6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Predicted 0  Predicted 1\n",
              "True 0         3208           44\n",
              "True 1           32          296"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b247631c-c71c-41dd-b246-09584fc34d71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted 0</th>\n",
              "      <th>Predicted 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True 0</th>\n",
              "      <td>3208</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True 1</th>\n",
              "      <td>32</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b247631c-c71c-41dd-b246-09584fc34d71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-ed60faba-415d-4664-b5f5-4cf6779e2181\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed60faba-415d-4664-b5f5-4cf6779e2181')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-ed60faba-415d-4664-b5f5-4cf6779e2181 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b247631c-c71c-41dd-b246-09584fc34d71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b247631c-c71c-41dd-b246-09584fc34d71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hubDgP7OwSmi",
        "outputId": "a7ffda17-2ca0-4c89-a436-3f45bc57286c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      3252\n",
            "           1       0.87      0.90      0.89       328\n",
            "\n",
            "    accuracy                           0.98      3580\n",
            "   macro avg       0.93      0.94      0.94      3580\n",
            "weighted avg       0.98      0.98      0.98      3580\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}